{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Objetivo do Modelo**:\n",
    "* Para cada um dos mais de 200 mil clientes, estimar o TPV mensal de Agosto à Dezembro de 2020. A métrica a ser utilizada na avaliação é o erro absoluto relativo. \n",
    "\n",
    "\n",
    "#### **Metodologia**:\n",
    "* **Preparação dos Dados**:\n",
    "    * Parsing e decomposição das datas\n",
    "    * Feature Engineering (label encoding, agrupamento, redução de categorias e muitos outros - mais detalhes no script `preprocessing.py`)\n",
    "    * Imputação de valores utilizando FFill.\n",
    "    * Padronização da variável Estado\n",
    "    * Criação de Lags e Diffs do TPV-Mensal\n",
    "\n",
    "\n",
    "* **Baseline**\n",
    "    * Média dos últimos meses (com vazamento de dados)\n",
    "    * Média dos últimos meses (sem vazamento de dados)\n",
    "    * TPV do último mes (só se aplica para validação)\n",
    "    \n",
    "    \n",
    "* **Definição do Modelo**\n",
    "    * Devido ao alto número de features categóricas e categorias, decidi por modelos ensemble.\n",
    "    * Foram treinados modelos em 3 algoritmos diferentes - RandomForest, CatBoost e LightGBM\n",
    "        * RandomForest foi escolhido por ser um bom baseline com hiperparâmetros padrão.\n",
    "        * Além da ótima perfomance padrão, o CatBoost foi escolhido por funcionar muito bem com dados categóricos.\n",
    "        * LightGBM lida muito bem com categóricos label encoded e permite maior controle dos hiperparâmetros, permitindo alcançar métricas melhores.\n",
    "    * RandomForest foi descartado por não ser eficiente com esse volume de dados.\n",
    "    \n",
    "* **Hiperparametrização**:\n",
    "    * Utilizei o Optuna (integrado ao LightGBM e API padrão) para realizar a hiperparametrização.\n",
    "\n",
    "\n",
    "* **Modelo Final**\n",
    "    * CatBOOST.\n",
    "\n",
    "\n",
    "* **Métricas de Avaliação**\n",
    "    * MAE - Mean Absolute Error. Se aproxima muito da métrica utilizada no desafio.\n",
    "    * Idealmente, eu acredito que para esse problema o uso do RMLSE poderia ser interessante também (considerando o range que o TPV-Value pode alcançar)\n",
    "\n",
    "\n",
    "* **Validação**\n",
    "    * O dataset foi separado em set de treino e teste de forma aleatória.\n",
    "    * Os modelos foram treinados no set de treino**, utilizando validação sliding window entre os meses de Março e Julho.\n",
    "        * **A única exceção foi o RandomForest, devido à ineficiência nesse volume de dados.\n",
    "    * Em seguida, os modelos foram aplicados no set de teste para verificar a capacidade de generalização.\n",
    "    \n",
    "* **Dataset Resultante**:\n",
    "    * `previsoes_ago_dez.csv`\n",
    "    \n",
    "\n",
    "**OBS.:** O LightGBM não oferece suporte para suprimir alguns warnings e como estou utilizando um loop para realizar o sliding window, as células que treinam o modelo acabam tendo um output bem poluído."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniando o Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "\n",
    "# Wrangling e Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import catboost as cb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nos datasets\n",
    "df = pd.read_csv('data/df_modelo.csv', parse_dates = ['mes_referencia'])\n",
    "df.drop(\"Unnamed: 0\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mes_referencia</th>\n",
       "      <th>TPV_mensal</th>\n",
       "      <th>Mês</th>\n",
       "      <th>Trimestre</th>\n",
       "      <th>Ano</th>\n",
       "      <th>tpv_ultimo_mes</th>\n",
       "      <th>diff_ultimo_mes</th>\n",
       "      <th>tpv_ultimo-1_mes</th>\n",
       "      <th>diff_ultimo-1_mes</th>\n",
       "      <th>...</th>\n",
       "      <th>is_missing_sub_segmento</th>\n",
       "      <th>persona</th>\n",
       "      <th>porte</th>\n",
       "      <th>tipo_documento</th>\n",
       "      <th>Estado</th>\n",
       "      <th>is_missing_Estado</th>\n",
       "      <th>tem_duplicados</th>\n",
       "      <th>StoneCreatedDate</th>\n",
       "      <th>diff_FirstTransaction_Created</th>\n",
       "      <th>Região</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>52,103.00</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>30</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2,549.80</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2.18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>86</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>10,010.96</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>126</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>9,935.00</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>150</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>9,453.05</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066739</th>\n",
       "      <td>206326</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>10,984.30</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>570.00</td>\n",
       "      <td>-405.00</td>\n",
       "      <td>570.00</td>\n",
       "      <td>-405.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066746</th>\n",
       "      <td>206327</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>50,545.80</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>49,672.30</td>\n",
       "      <td>31,805.90</td>\n",
       "      <td>49,672.30</td>\n",
       "      <td>31,805.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066759</th>\n",
       "      <td>206328</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>4,680.00</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>3,810.00</td>\n",
       "      <td>-90.00</td>\n",
       "      <td>3,810.00</td>\n",
       "      <td>-90.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066767</th>\n",
       "      <td>206329</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>60,213.99</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>61,699.27</td>\n",
       "      <td>5,998.70</td>\n",
       "      <td>61,699.27</td>\n",
       "      <td>5,998.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1.68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066771</th>\n",
       "      <td>206330</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>16,389.47</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>15,098.04</td>\n",
       "      <td>-3,237.58</td>\n",
       "      <td>15,098.04</td>\n",
       "      <td>-3,237.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3066772 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id mes_referencia  TPV_mensal  Mês  Trimestre   Ano  \\\n",
       "466          29     2017-07-31   52,103.00    7          3  2017   \n",
       "503          30     2017-07-31    2,549.80    7          3  2017   \n",
       "1366         86     2017-07-31   10,010.96    7          3  2017   \n",
       "1934        126     2017-07-31    9,935.00    7          3  2017   \n",
       "2277        150     2017-07-31    9,453.05    7          3  2017   \n",
       "...         ...            ...         ...  ...        ...   ...   \n",
       "3066739  206326     2020-07-31   10,984.30    7          3  2020   \n",
       "3066746  206327     2020-07-31   50,545.80    7          3  2020   \n",
       "3066759  206328     2020-07-31    4,680.00    7          3  2020   \n",
       "3066767  206329     2020-07-31   60,213.99    7          3  2020   \n",
       "3066771  206330     2020-07-31   16,389.47    7          3  2020   \n",
       "\n",
       "         tpv_ultimo_mes  diff_ultimo_mes  tpv_ultimo-1_mes  diff_ultimo-1_mes  \\\n",
       "466                 nan              nan               nan                nan   \n",
       "503                 nan              nan               nan                nan   \n",
       "1366                nan              nan               nan                nan   \n",
       "1934                nan              nan               nan                nan   \n",
       "2277                nan              nan               nan                nan   \n",
       "...                 ...              ...               ...                ...   \n",
       "3066739          570.00          -405.00            570.00            -405.00   \n",
       "3066746       49,672.30        31,805.90         49,672.30          31,805.90   \n",
       "3066759        3,810.00           -90.00          3,810.00             -90.00   \n",
       "3066767       61,699.27         5,998.70         61,699.27           5,998.70   \n",
       "3066771       15,098.04        -3,237.58         15,098.04          -3,237.58   \n",
       "\n",
       "         ...  is_missing_sub_segmento  persona  porte  tipo_documento  Estado  \\\n",
       "466      ...                        0       11      6               2       6   \n",
       "503      ...                        0        8      3               2      10   \n",
       "1366     ...                        0       11      5               2      19   \n",
       "1934     ...                        0        6      4               2      26   \n",
       "2277     ...                        0        7      3               2      10   \n",
       "...      ...                      ...      ...    ...             ...     ...   \n",
       "3066739  ...                        0        7      4               1      26   \n",
       "3066746  ...                        0        7      4               2      16   \n",
       "3066759  ...                        0        2      2               1      19   \n",
       "3066767  ...                        0       11      6               2      10   \n",
       "3066771  ...                        0        8      4               1       2   \n",
       "\n",
       "         is_missing_Estado  tem_duplicados  StoneCreatedDate  \\\n",
       "466                      0               1                36   \n",
       "503                      0               1                37   \n",
       "1366                     0               0                64   \n",
       "1934                     0               1                35   \n",
       "2277                     0               1                 9   \n",
       "...                    ...             ...               ...   \n",
       "3066739                  0               0                87   \n",
       "3066746                  0               0                95   \n",
       "3066759                  0               0                89   \n",
       "3066767                  0               0                94   \n",
       "3066771                  0               0                98   \n",
       "\n",
       "         diff_FirstTransaction_Created  Região  \n",
       "466                               0.82       0  \n",
       "503                               2.18       4  \n",
       "1366                              1.26       4  \n",
       "1934                              2.20       4  \n",
       "2277                              2.60       4  \n",
       "...                                ...     ...  \n",
       "3066739                           1.26       4  \n",
       "3066746                           0.39       2  \n",
       "3066759                           0.82       4  \n",
       "3066767                           1.68       4  \n",
       "3066771                           1.40       3  \n",
       "\n",
       "[3066772 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['mes_referencia', 'id'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando sets - train e test set\n",
    "all_ids = np.array(df.id.unique())\n",
    "\n",
    "np.random.seed(42)\n",
    "test_ids = np.random.choice(all_ids, size = round(0.15*len(all_ids)))\n",
    "\n",
    "df_test = df[df.id.isin(test_ids)]\n",
    "df_train = df[~df.id.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez separados os sets de treino e de teste e confirmado que está tudo correto, podemos calcular o score baseline. Irei utilizar os últimos meses do dataset (Mar/2020 - Jul/2020) para testar o funcionamento dos modelos. Após a previsão do primeiro mês, o modelo incorporará o mês previsto para prever o próximo (sliding window). \n",
    "\n",
    "### Baselines\n",
    "\n",
    "Irei utilizar 3 baselines para comparar os resultados.\n",
    "\n",
    "* Erro comparando a venda atual com a venda do último mês.\n",
    "    * Esse é um score baseline considerado relativamente forte para séries temporais, principalmente quando atribuídas à vendas ou saídas de produto.\n",
    "* Erro comparando a venda atual com a média das vendas até o mês atual.\n",
    "    * Definido de acordo com o PDF do case.\n",
    "* Erro comparando a venda atual com a média das vendas incluindo o mês atual e seguintes, se aplicável.\n",
    "    * Também definido de acordo com o PDF do case, nesse caso ocorre vazamento de dados o que aumenta o score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mês 3 - Error 7490.14150\n",
      "Mês 4 - Error 7544.06240\n",
      "Mês 5 - Error 6555.97363\n",
      "Mês 6 - Error 5691.07836\n",
      "Mês 7 - Error 6123.64362\n",
      "Mean Error = 6680.97990\n"
     ]
    }
   ],
   "source": [
    "# Definindo Baselines - Venda do Ultimo Mes\n",
    "\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):\n",
    "    val = df_train[(df_train['Ano'] == 2020) & (df_train['Mês'] == mes)]\n",
    "\n",
    "    val = val.fillna(0)\n",
    "    pred = val['tpv_ultimo_mes'].values\n",
    "\n",
    "    error = mean_absolute_error(val['TPV_mensal'].values, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mês 3 - Error 6942.39260\n",
      "Mês 4 - Error 9223.32410\n",
      "Mês 5 - Error 8936.66330\n",
      "Mês 6 - Error 8427.84512\n",
      "Mês 7 - Error 9413.33451\n",
      "Mean Error = 8588.71193\n"
     ]
    }
   ],
   "source": [
    "# Definindo Baselines - #2 Média dos últimos meses (nao conta em frente)\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):     \n",
    "    val = df_train[(df_train['Ano'] == 2020) & (df_train['Mês'] == mes)]\n",
    "    ids = val['id'].unique()\n",
    "    \n",
    "    pred = df_train[(df_train['id'].isin(ids)) & (df_train['mes_referencia'] < np.datetime64(f'2020-0{mes + 1}'))]\\\n",
    "                                                                            .groupby('id')['TPV_mensal']\\\n",
    "                                                                            .mean()\n",
    "\n",
    "    error = mean_absolute_error(val['TPV_mensal'].values, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mês 3 - Error 6589.17186\n",
      "Mês 4 - Error 8705.23750\n",
      "Mês 5 - Error 8215.67843\n",
      "Mês 6 - Error 7805.07531\n",
      "Mês 7 - Error 9413.33451\n",
      "Mean Error = 8145.69952\n"
     ]
    }
   ],
   "source": [
    "# Definindo Baselines - #3 Média de todos os últimos meses\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):     \n",
    "    val = df_train[(df_train['Ano'] == 2020) & (df_train['Mês'] == mes)]\n",
    "    ids = val['id'].unique()\n",
    "    \n",
    "    pred = df_train[(df_train['id'].isin(ids))].groupby('id')['TPV_mensal'].mean()\n",
    "\n",
    "    error = mean_absolute_error(val['TPV_mensal'].values, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, os scores entre as baselines:\n",
    "1. Erro da Venda do Último Mês: **6680.97**\n",
    "2. Erro da Média de Todos os Meses: **8145.69**\n",
    "3. Erro da Média dos últimos meses (nao conta em frente): **8588.71**\n",
    "\n",
    "### RF Default e HiperParametrização do LightGBM e do CatBoost\n",
    "\n",
    "**Obs.:** Esses não são os melhores hiperparametros possíveis. Talvez seja possível aumentar a precisão mas devido ao tempo para a entrega, reduzi o tempo de busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mês 3 - Error 7697.02995\n",
      "Mês 4 - Error 8197.78799\n",
      "Mês 5 - Error 6590.88806\n",
      "Mês 6 - Error 5634.51405\n",
      "Mês 7 - Error 5898.83429\n",
      "Mean Error = 6803.81086\n"
     ]
    }
   ],
   "source": [
    "#### Random Forest\n",
    "\n",
    "# Hiperparametros padrao\n",
    "\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):\n",
    "    \n",
    "    # RF foi extremamente ineficiente no set de treino e decidi treina-lo apenas no set de test.\n",
    "    \n",
    "    train = df_test[df_test['mes_referencia'] < np.datetime64(f'2020-0{mes}')]\n",
    "    val = df_test[(df_test['Ano'] == 2020) & (df_test['Mês'] == mes)]\n",
    "    \n",
    "    # RF não lida c/ valores NaN por padrão\n",
    "    \n",
    "    val = val.fillna(0)\n",
    "    train = train.fillna(0)\n",
    "    \n",
    "    X_train, X_test = train.drop(['TPV_mensal', 'mes_referencia'], axis=1), val.drop(['TPV_mensal', 'mes_referencia'], axis=1)\n",
    "    y_train, y_test = train['TPV_mensal'].values, val['TPV_mensal'].values\n",
    "\n",
    "    # Instancia e Fita o Modelo\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, n_jobs=8, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(y_test, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 16:13:27,701]\u001b[0m A new study created in memory with name: no-name-28b9f56e-3df5-4506-b9b5-7255e90dead2\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AC:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 28, 29, 31, 33, 35, 36, 37, 38, 43]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6732.906329:   0%|                                                  | 0/7 [00:16<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6732.906329:  14%|######                                    | 1/7 [00:16<01:41, 16.97s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:13:44,690]\u001b[0m Trial 0 finished with value: 6732.906329264007 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 6732.906329264007.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6732.906329:  14%|######                                    | 1/7 [00:16<01:41, 16.97s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  14%|######                                    | 1/7 [00:32<01:41, 16.97s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  29%|############                              | 2/7 [00:32<01:23, 16.68s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:14:00,698]\u001b[0m Trial 1 finished with value: 6729.845245381227 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 6729.845245381227.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  29%|############                              | 2/7 [00:32<01:23, 16.68s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  29%|############                              | 2/7 [00:47<01:23, 16.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  43%|##################                        | 3/7 [00:47<01:04, 16.07s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:14:15,344]\u001b[0m Trial 2 finished with value: 6752.072253171127 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 6729.845245381227.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  43%|##################                        | 3/7 [00:47<01:04, 16.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  43%|##################                        | 3/7 [01:01<01:04, 16.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  57%|########################                  | 4/7 [01:01<00:45, 15.26s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:14:28,728]\u001b[0m Trial 3 finished with value: 6754.9718010202405 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 6729.845245381227.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  57%|########################                  | 4/7 [01:01<00:45, 15.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  57%|########################                  | 4/7 [01:13<00:45, 15.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  71%|##############################            | 5/7 [01:13<00:28, 14.45s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:14:41,277]\u001b[0m Trial 4 finished with value: 6802.564608883327 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 6729.845245381227.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  71%|##############################            | 5/7 [01:13<00:28, 14.45s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  71%|##############################            | 5/7 [01:27<00:28, 14.45s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  86%|####################################      | 6/7 [01:27<00:14, 14.19s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:14:54,872]\u001b[0m Trial 5 finished with value: 6746.557839824777 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 6729.845245381227.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  86%|####################################      | 6/7 [01:27<00:14, 14.19s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245:  86%|####################################      | 6/7 [01:42<00:14, 14.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6729.845245: 100%|##########################################| 7/7 [01:42<00:00, 14.43s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:15:09,857]\u001b[0m Trial 6 finished with value: 6736.865270208148 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 6729.845245381227.\u001b[0m\n",
      "feature_fraction, val_score: 6729.845245: 100%|##########################################| 7/7 [01:42<00:00, 14.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6729.845245:   0%|                                                       | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6578.761249:   0%|                                                       | 0/20 [00:18<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6578.761249:   5%|##3                                            | 1/20 [00:18<05:45, 18.17s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:15:28,049]\u001b[0m Trial 7 finished with value: 6578.761248932194 and parameters: {'num_leaves': 53}. Best is trial 7 with value: 6578.761248932194.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6578.761249:   5%|##3                                            | 1/20 [00:18<05:45, 18.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6578.761249:   5%|##3                                            | 1/20 [00:40<05:45, 18.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6578.761249:  10%|####7                                          | 2/20 [00:40<05:51, 19.55s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:15:50,818]\u001b[0m Trial 8 finished with value: 6674.951925790343 and parameters: {'num_leaves': 198}. Best is trial 7 with value: 6578.761248932194.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6578.761249:  10%|####7                                          | 2/20 [00:40<05:51, 19.55s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  10%|####7                                          | 2/20 [01:05<05:51, 19.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  15%|#######                                        | 3/20 [01:05<05:56, 20.95s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:16:15,045]\u001b[0m Trial 9 finished with value: 6483.941219199616 and parameters: {'num_leaves': 192}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  15%|#######                                        | 3/20 [01:05<05:56, 20.95s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  15%|#######                                        | 3/20 [01:23<05:56, 20.95s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  20%|#########4                                     | 4/20 [01:23<05:22, 20.14s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:16:33,275]\u001b[0m Trial 10 finished with value: 6623.881193238461 and parameters: {'num_leaves': 105}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  20%|#########4                                     | 4/20 [01:23<05:22, 20.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  20%|#########4                                     | 4/20 [01:38<05:22, 20.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  25%|###########7                                   | 5/20 [01:38<04:37, 18.49s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:16:47,912]\u001b[0m Trial 11 finished with value: 6771.969581255163 and parameters: {'num_leaves': 27}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  25%|###########7                                   | 5/20 [01:38<04:37, 18.49s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  25%|###########7                                   | 5/20 [01:56<04:37, 18.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  30%|##############1                                | 6/20 [01:56<04:20, 18.59s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:17:06,726]\u001b[0m Trial 12 finished with value: 6574.534485429196 and parameters: {'num_leaves': 62}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  30%|##############1                                | 6/20 [01:56<04:20, 18.59s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  30%|##############1                                | 6/20 [02:11<04:20, 18.59s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  35%|################4                              | 7/20 [02:11<03:47, 17.50s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:17:21,695]\u001b[0m Trial 13 finished with value: 6707.000883053656 and parameters: {'num_leaves': 55}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  35%|################4                              | 7/20 [02:11<03:47, 17.50s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  35%|################4                              | 7/20 [02:28<03:47, 17.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  40%|##################8                            | 8/20 [02:28<03:27, 17.29s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:17:38,499]\u001b[0m Trial 14 finished with value: 6659.255265742363 and parameters: {'num_leaves': 47}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  40%|##################8                            | 8/20 [02:28<03:27, 17.29s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  40%|##################8                            | 8/20 [02:44<03:27, 17.29s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  45%|#####################1                         | 9/20 [02:44<03:06, 16.92s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:17:54,548]\u001b[0m Trial 15 finished with value: 6656.922772479966 and parameters: {'num_leaves': 52}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  45%|#####################1                         | 9/20 [02:44<03:06, 16.92s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  45%|#####################1                         | 9/20 [03:06<03:06, 16.92s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  50%|#######################                       | 10/20 [03:06<03:03, 18.38s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:18:16,331]\u001b[0m Trial 16 finished with value: 6604.047770058167 and parameters: {'num_leaves': 171}. Best is trial 9 with value: 6483.941219199616.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6483.941219:  50%|#######################                       | 10/20 [03:06<03:03, 18.38s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  50%|#######################                       | 10/20 [03:34<03:03, 18.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  55%|#########################3                    | 11/20 [03:34<03:12, 21.39s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:18:44,751]\u001b[0m Trial 17 finished with value: 6428.9355126109085 and parameters: {'num_leaves': 251}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  55%|#########################3                    | 11/20 [03:34<03:12, 21.39s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  55%|#########################3                    | 11/20 [04:00<03:12, 21.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  60%|###########################6                  | 12/20 [04:00<03:00, 22.61s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:19:10,208]\u001b[0m Trial 18 finished with value: 6621.850149507217 and parameters: {'num_leaves': 256}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  60%|###########################6                  | 12/20 [04:00<03:00, 22.61s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  60%|###########################6                  | 12/20 [04:27<03:00, 22.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  65%|#############################9                | 13/20 [04:27<02:48, 24.08s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:19:37,739]\u001b[0m Trial 19 finished with value: 6531.539656638328 and parameters: {'num_leaves': 239}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  65%|#############################9                | 13/20 [04:27<02:48, 24.08s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  65%|#############################9                | 13/20 [04:55<02:48, 24.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  70%|################################1             | 14/20 [04:55<02:30, 25.01s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:20:04,911]\u001b[0m Trial 20 finished with value: 6463.8869741328945 and parameters: {'num_leaves': 206}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  70%|################################1             | 14/20 [04:55<02:30, 25.01s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  70%|################################1             | 14/20 [05:21<02:30, 25.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  75%|##################################5           | 15/20 [05:21<02:07, 25.52s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:20:31,602]\u001b[0m Trial 21 finished with value: 6450.0048611687735 and parameters: {'num_leaves': 229}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  75%|##################################5           | 15/20 [05:21<02:07, 25.52s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  75%|##################################5           | 15/20 [05:48<02:07, 25.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  80%|####################################8         | 16/20 [05:48<01:42, 25.75s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:20:57,890]\u001b[0m Trial 22 finished with value: 6621.850149507217 and parameters: {'num_leaves': 256}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  80%|####################################8         | 16/20 [05:48<01:42, 25.75s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  80%|####################################8         | 16/20 [06:11<01:42, 25.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  85%|#######################################1      | 17/20 [06:11<01:15, 25.03s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:21:21,223]\u001b[0m Trial 23 finished with value: 6559.330093535195 and parameters: {'num_leaves': 141}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  85%|#######################################1      | 17/20 [06:11<01:15, 25.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  85%|#######################################1      | 17/20 [06:38<01:15, 25.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  90%|#########################################4    | 18/20 [06:38<00:51, 25.61s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:21:48,213]\u001b[0m Trial 24 finished with value: 6547.94339540506 and parameters: {'num_leaves': 228}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  90%|#########################################4    | 18/20 [06:38<00:51, 25.61s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  90%|#########################################4    | 18/20 [07:00<00:51, 25.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  95%|###########################################6  | 19/20 [07:00<00:24, 24.73s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:22:10,866]\u001b[0m Trial 25 finished with value: 6601.617125751323 and parameters: {'num_leaves': 164}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  95%|###########################################6  | 19/20 [07:01<00:24, 24.73s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513:  95%|###########################################6  | 19/20 [07:20<00:24, 24.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6428.935513: 100%|##############################################| 20/20 [07:20<00:00, 23.10s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:22:30,169]\u001b[0m Trial 26 finished with value: 6646.1243125035235 and parameters: {'num_leaves': 107}. Best is trial 17 with value: 6428.9355126109085.\u001b[0m\n",
      "num_leaves, val_score: 6428.935513: 100%|##############################################| 20/20 [07:20<00:00, 22.02s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6428.935513:   0%|                                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 6428.935513:   0%|                                                          | 0/10 [00:35<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6428.935513:  10%|#####                                             | 1/10 [00:35<05:17, 35.33s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:23:05,536]\u001b[0m Trial 27 finished with value: 6534.673988074157 and parameters: {'bagging_fraction': 0.8511278394074961, 'bagging_freq': 2}. Best is trial 27 with value: 6534.673988074157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 6428.935513:  10%|#####                                             | 1/10 [00:35<05:17, 35.33s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 6428.935513:  10%|#####                                             | 1/10 [01:10<05:17, 35.33s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6428.935513:  20%|##########                                        | 2/10 [01:10<04:41, 35.22s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:23:40,524]\u001b[0m Trial 28 finished with value: 6455.009075369295 and parameters: {'bagging_fraction': 0.9055070011774913, 'bagging_freq': 7}. Best is trial 28 with value: 6455.009075369295.\u001b[0m\n",
      "bagging, val_score: 6428.935513:  20%|##########                                        | 2/10 [01:10<04:41, 35.17s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'regression', 'metric': 'l1', 'boosting': 'gbdt', 'verbosity': 0, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 251, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100}\n",
      "Mês 3 - Error 7325.74436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 16:23:41,173]\u001b[0m A new study created in memory with name: no-name-7a56ada3-927b-4867-b7a5-26f404d4ab4a\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AC:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 28, 29, 31, 33, 35, 36, 37, 38, 43]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:   0%|                                                  | 0/7 [00:36<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  14%|######                                    | 1/7 [00:36<03:36, 36.16s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:24:17,356]\u001b[0m Trial 0 finished with value: 6450.983190970341 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 6450.983190970341.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  14%|######                                    | 1/7 [00:36<03:36, 36.16s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  14%|######                                    | 1/7 [00:56<03:36, 36.16s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  29%|############                              | 2/7 [00:56<02:36, 31.27s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:24:37,208]\u001b[0m Trial 1 finished with value: 6658.609420331486 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 6450.983190970341.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  29%|############                              | 2/7 [00:56<02:36, 31.27s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  29%|############                              | 2/7 [01:26<02:36, 31.27s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  43%|##################                        | 3/7 [01:26<02:04, 31.17s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:25:08,167]\u001b[0m Trial 2 finished with value: 6479.89320897121 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 6450.983190970341.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  43%|##################                        | 3/7 [01:26<02:04, 31.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  43%|##################                        | 3/7 [01:56<02:04, 31.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  57%|########################                  | 4/7 [01:56<01:31, 30.61s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:25:37,455]\u001b[0m Trial 3 finished with value: 6510.854957432558 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 6450.983190970341.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  57%|########################                  | 4/7 [01:56<01:31, 30.61s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  57%|########################                  | 4/7 [02:12<01:31, 30.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  71%|##############################            | 5/7 [02:12<00:52, 26.22s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:25:53,426]\u001b[0m Trial 4 finished with value: 6803.627970104374 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 6450.983190970341.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6450.983191:  71%|##############################            | 5/7 [02:12<00:52, 26.22s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6239.633544:  71%|##############################            | 5/7 [03:02<00:52, 26.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6239.633544:  86%|####################################      | 6/7 [03:02<00:33, 33.35s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:26:43,427]\u001b[0m Trial 5 finished with value: 6239.6335438492515 and parameters: {'feature_fraction': 0.6}. Best is trial 5 with value: 6239.6335438492515.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6239.633544:  86%|####################################      | 6/7 [03:02<00:33, 33.35s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6239.633544:  86%|####################################      | 6/7 [03:22<00:33, 33.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6239.633544: 100%|##########################################| 7/7 [03:22<00:00, 29.41s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:27:03,645]\u001b[0m Trial 6 finished with value: 6683.226319886745 and parameters: {'feature_fraction': 0.8}. Best is trial 5 with value: 6239.6335438492515.\u001b[0m\n",
      "feature_fraction, val_score: 6239.633544: 100%|##########################################| 7/7 [03:22<00:00, 28.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6239.633544:   0%|                                                       | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6239.633544:   0%|                                                       | 0/20 [00:21<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6239.633544:   5%|##3                                            | 1/20 [00:21<06:53, 21.77s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:27:25,443]\u001b[0m Trial 7 finished with value: 6483.7324656573255 and parameters: {'num_leaves': 126}. Best is trial 7 with value: 6483.7324656573255.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6239.633544:   5%|##3                                            | 1/20 [00:21<06:53, 21.77s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5689.336990:   5%|##3                                            | 1/20 [01:42<06:53, 21.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5689.336990:  10%|####7                                          | 2/20 [01:42<11:51, 39.50s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:28:46,316]\u001b[0m Trial 8 finished with value: 5689.336989780374 and parameters: {'num_leaves': 130}. Best is trial 8 with value: 5689.336989780374.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5689.336990:  10%|####7                                          | 2/20 [01:42<11:51, 39.50s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  10%|####7                                          | 2/20 [03:26<11:51, 39.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  15%|#######                                        | 3/20 [03:26<16:40, 58.84s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:30:30,289]\u001b[0m Trial 9 finished with value: 5394.874073240784 and parameters: {'num_leaves': 214}. Best is trial 9 with value: 5394.874073240784.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  15%|#######                                        | 3/20 [03:26<16:40, 58.84s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  15%|#######                                        | 3/20 [03:47<16:40, 58.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  20%|#########4                                     | 4/20 [03:47<12:40, 47.54s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:30:51,457]\u001b[0m Trial 10 finished with value: 6990.3075735073 and parameters: {'num_leaves': 11}. Best is trial 9 with value: 5394.874073240784.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  20%|#########4                                     | 4/20 [03:47<12:40, 47.54s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  20%|#########4                                     | 4/20 [05:10<12:40, 47.54s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  25%|###########7                                   | 5/20 [05:10<14:29, 57.94s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:32:13,684]\u001b[0m Trial 11 finished with value: 5665.810217720771 and parameters: {'num_leaves': 102}. Best is trial 9 with value: 5394.874073240784.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  25%|###########7                                   | 5/20 [05:10<14:29, 57.94s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  25%|###########7                                   | 5/20 [06:30<14:29, 57.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  30%|##############1                                | 6/20 [06:30<15:05, 64.65s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:33:34,000]\u001b[0m Trial 12 finished with value: 5667.103919946869 and parameters: {'num_leaves': 84}. Best is trial 9 with value: 5394.874073240784.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  30%|##############1                                | 6/20 [06:30<15:05, 64.65s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  30%|##############1                                | 6/20 [06:49<15:05, 64.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 5394.874073:  35%|################4                              | 7/20 [06:49<11:04, 51.12s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:33:53,526]\u001b[0m Trial 13 finished with value: 6579.93320134156 and parameters: {'num_leaves': 91}. Best is trial 9 with value: 5394.874073240784.\u001b[0m\n",
      "num_leaves, val_score: 5394.874073:  35%|################4                              | 7/20 [06:49<12:41, 58.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'regression', 'metric': 'l1', 'boosting': 'gbdt', 'verbosity': 0, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 214, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100}\n",
      "Mês 4 - Error 7588.97513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 16:33:56,691]\u001b[0m A new study created in memory with name: no-name-71aa40d9-2a94-4f6a-9b48-2cc1b67a1984\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AC:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 28, 29, 31, 33, 35, 36, 37, 38, 43]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 7146.754451:   0%|                                                  | 0/7 [00:11<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 7146.754451:  14%|######                                    | 1/7 [00:11<01:09, 11.66s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:34:08,375]\u001b[0m Trial 0 finished with value: 7146.754450761074 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 7146.754450761074.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 7146.754451:  14%|######                                    | 1/7 [00:11<01:09, 11.66s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  14%|######                                    | 1/7 [00:25<01:09, 11.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  29%|############                              | 2/7 [00:25<01:01, 12.26s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:34:22,046]\u001b[0m Trial 1 finished with value: 6983.983777035065 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 6983.983777035065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  29%|############                              | 2/7 [00:25<01:01, 12.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  29%|############                              | 2/7 [00:36<01:01, 12.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  43%|##################                        | 3/7 [00:36<00:48, 12.00s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:34:33,446]\u001b[0m Trial 2 finished with value: 7073.685505760867 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 6983.983777035065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  43%|##################                        | 3/7 [00:36<00:48, 12.00s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  43%|##################                        | 3/7 [00:50<00:48, 12.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  57%|########################                  | 4/7 [00:50<00:37, 12.56s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:34:47,297]\u001b[0m Trial 3 finished with value: 6995.890971417166 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 6983.983777035065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  57%|########################                  | 4/7 [00:50<00:37, 12.56s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  57%|########################                  | 4/7 [01:03<00:37, 12.56s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  71%|##############################            | 5/7 [01:03<00:25, 12.54s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:34:59,809]\u001b[0m Trial 4 finished with value: 7176.320478494071 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 6983.983777035065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  71%|##############################            | 5/7 [01:03<00:25, 12.54s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  71%|##############################            | 5/7 [01:16<00:25, 12.54s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  86%|####################################      | 6/7 [01:16<00:12, 12.73s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:35:12,963]\u001b[0m Trial 5 finished with value: 7001.397928314195 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 6983.983777035065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  86%|####################################      | 6/7 [01:16<00:12, 12.73s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777:  86%|####################################      | 6/7 [01:28<00:12, 12.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6983.983777: 100%|##########################################| 7/7 [01:28<00:00, 12.55s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:35:25,099]\u001b[0m Trial 6 finished with value: 7037.73016905391 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 6983.983777035065.\u001b[0m\n",
      "feature_fraction, val_score: 6983.983777: 100%|##########################################| 7/7 [01:28<00:00, 12.63s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6983.983777:   0%|                                                       | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6703.336335:   0%|                                                       | 0/20 [00:22<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6703.336335:   5%|##3                                            | 1/20 [00:22<07:02, 22.21s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:35:47,337]\u001b[0m Trial 7 finished with value: 6703.336334921081 and parameters: {'num_leaves': 141}. Best is trial 7 with value: 6703.336334921081.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6703.336335:   5%|##3                                            | 1/20 [00:22<07:02, 22.21s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6703.336335:   5%|##3                                            | 1/20 [00:40<07:02, 22.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6703.336335:  10%|####7                                          | 2/20 [00:40<06:18, 21.03s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:36:05,618]\u001b[0m Trial 8 finished with value: 6802.457397663737 and parameters: {'num_leaves': 83}. Best is trial 7 with value: 6703.336334921081.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6703.336335:  10%|####7                                          | 2/20 [00:40<06:18, 21.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  10%|####7                                          | 2/20 [01:04<06:18, 21.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  15%|#######                                        | 3/20 [01:04<06:11, 21.83s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:36:29,319]\u001b[0m Trial 9 finished with value: 6636.5673240523065 and parameters: {'num_leaves': 161}. Best is trial 9 with value: 6636.5673240523065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  15%|#######                                        | 3/20 [01:04<06:11, 21.83s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  15%|#######                                        | 3/20 [01:23<06:11, 21.83s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  20%|#########4                                     | 4/20 [01:23<05:39, 21.22s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:36:49,095]\u001b[0m Trial 10 finished with value: 6805.315198295176 and parameters: {'num_leaves': 99}. Best is trial 9 with value: 6636.5673240523065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  20%|#########4                                     | 4/20 [01:23<05:39, 21.22s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  20%|#########4                                     | 4/20 [01:43<05:39, 21.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  25%|###########7                                   | 5/20 [01:43<05:11, 20.78s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:37:08,847]\u001b[0m Trial 11 finished with value: 6784.958993522964 and parameters: {'num_leaves': 107}. Best is trial 9 with value: 6636.5673240523065.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6636.567324:  25%|###########7                                   | 5/20 [01:43<05:11, 20.78s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6549.737815:  25%|###########7                                   | 5/20 [02:10<05:11, 20.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6549.737815:  30%|##############1                                | 6/20 [02:10<05:18, 22.72s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:37:36,109]\u001b[0m Trial 12 finished with value: 6549.737814533628 and parameters: {'num_leaves': 193}. Best is trial 12 with value: 6549.737814533628.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6549.737815:  30%|##############1                                | 6/20 [02:11<05:18, 22.72s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6549.737815:  30%|##############1                                | 6/20 [02:31<05:18, 22.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6549.737815:  35%|################4                              | 7/20 [02:31<04:48, 22.17s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:37:57,003]\u001b[0m Trial 13 finished with value: 6718.009535959942 and parameters: {'num_leaves': 121}. Best is trial 12 with value: 6549.737814533628.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6549.737815:  35%|################4                              | 7/20 [02:31<04:48, 22.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  35%|################4                              | 7/20 [03:00<04:48, 22.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  40%|##################8                            | 8/20 [03:00<04:49, 24.11s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:38:25,630]\u001b[0m Trial 14 finished with value: 6537.48685256527 and parameters: {'num_leaves': 225}. Best is trial 14 with value: 6537.48685256527.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  40%|##################8                            | 8/20 [03:00<04:49, 24.11s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.146508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  40%|##################8                            | 8/20 [03:26<04:49, 24.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  45%|#####################1                         | 9/20 [03:26<04:29, 24.54s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:38:51,166]\u001b[0m Trial 15 finished with value: 6567.652945709282 and parameters: {'num_leaves': 157}. Best is trial 14 with value: 6537.48685256527.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  45%|#####################1                         | 9/20 [03:26<04:29, 24.54s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  45%|#####################1                         | 9/20 [03:45<04:29, 24.54s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  50%|#######################                       | 10/20 [03:45<03:50, 23.03s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:39:10,676]\u001b[0m Trial 16 finished with value: 6805.315198295176 and parameters: {'num_leaves': 99}. Best is trial 14 with value: 6537.48685256527.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  50%|#######################                       | 10/20 [03:45<03:50, 23.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  50%|#######################                       | 10/20 [04:15<03:50, 23.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  55%|#########################3                    | 11/20 [04:15<03:45, 25.07s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:39:40,513]\u001b[0m Trial 17 finished with value: 6559.6432660719875 and parameters: {'num_leaves': 255}. Best is trial 14 with value: 6537.48685256527.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6537.486853:  55%|#########################3                    | 11/20 [04:15<03:45, 25.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6498.179417:  55%|#########################3                    | 11/20 [04:44<03:45, 25.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6498.179417:  60%|###########################6                  | 12/20 [04:44<03:31, 26.43s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:40:10,107]\u001b[0m Trial 18 finished with value: 6498.179416976992 and parameters: {'num_leaves': 233}. Best is trial 18 with value: 6498.179416976992.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6498.179417:  60%|###########################6                  | 12/20 [04:45<03:31, 26.43s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6498.179417:  60%|###########################6                  | 12/20 [04:57<03:31, 26.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6498.179417:  65%|#############################9                | 13/20 [04:57<02:35, 22.15s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:40:22,267]\u001b[0m Trial 19 finished with value: 7370.531639247427 and parameters: {'num_leaves': 9}. Best is trial 18 with value: 6498.179416976992.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6498.179417:  65%|#############################9                | 13/20 [04:57<02:35, 22.15s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  65%|#############################9                | 13/20 [05:27<02:35, 22.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  70%|################################1             | 14/20 [05:27<02:27, 24.63s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:40:52,673]\u001b[0m Trial 20 finished with value: 6426.615128589336 and parameters: {'num_leaves': 252}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  70%|################################1             | 14/20 [05:27<02:27, 24.63s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  70%|################################1             | 14/20 [05:55<02:27, 24.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  75%|##################################5           | 15/20 [05:55<02:07, 25.56s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:41:20,431]\u001b[0m Trial 21 finished with value: 6574.263882200927 and parameters: {'num_leaves': 239}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  75%|##################################5           | 15/20 [05:55<02:07, 25.56s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  75%|##################################5           | 15/20 [06:22<02:07, 25.56s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  80%|####################################8         | 16/20 [06:22<01:43, 25.98s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:41:47,381]\u001b[0m Trial 22 finished with value: 6548.484762776504 and parameters: {'num_leaves': 208}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  80%|####################################8         | 16/20 [06:22<01:43, 25.98s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.141110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  80%|####################################8         | 16/20 [06:48<01:43, 25.98s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  85%|#######################################1      | 17/20 [06:48<01:17, 25.93s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:42:13,204]\u001b[0m Trial 23 finished with value: 6570.058128722948 and parameters: {'num_leaves': 187}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  85%|#######################################1      | 17/20 [06:48<01:17, 25.93s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.151780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  85%|#######################################1      | 17/20 [07:18<01:17, 25.93s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  90%|#########################################4    | 18/20 [07:18<00:54, 27.31s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:42:43,724]\u001b[0m Trial 24 finished with value: 6426.615128589336 and parameters: {'num_leaves': 252}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  90%|#########################################4    | 18/20 [07:18<00:54, 27.31s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  90%|#########################################4    | 18/20 [07:34<00:54, 27.31s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  95%|###########################################6  | 19/20 [07:34<00:23, 23.87s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:42:59,558]\u001b[0m Trial 25 finished with value: 6884.209605346673 and parameters: {'num_leaves': 55}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  95%|###########################################6  | 19/20 [07:34<00:23, 23.87s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129:  95%|###########################################6  | 19/20 [08:01<00:23, 23.87s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6426.615129: 100%|##############################################| 20/20 [08:01<00:00, 24.88s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:43:26,796]\u001b[0m Trial 26 finished with value: 6570.815435047512 and parameters: {'num_leaves': 210}. Best is trial 20 with value: 6426.615128589336.\u001b[0m\n",
      "num_leaves, val_score: 6426.615129: 100%|##############################################| 20/20 [08:01<00:00, 24.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6426.615129:   0%|                                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 6426.615129:   0%|                                                          | 0/10 [00:35<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6426.615129:  10%|#####                                             | 1/10 [00:35<05:18, 35.41s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:44:02,231]\u001b[0m Trial 27 finished with value: 6509.235291672037 and parameters: {'bagging_fraction': 0.9977206746170009, 'bagging_freq': 3}. Best is trial 27 with value: 6509.235291672037.\u001b[0m\n",
      "bagging, val_score: 6426.615129:  10%|#####                                             | 1/10 [00:35<05:18, 35.43s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'regression', 'metric': 'l1', 'boosting': 'gbdt', 'verbosity': 0, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 252, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100}\n",
      "Mês 5 - Error 6781.64634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 16:44:03,021]\u001b[0m A new study created in memory with name: no-name-aaa68392-45b2-4d76-b17b-3a4d819c8859\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AC:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 28, 29, 31, 33, 35, 36, 37, 38, 43]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:   0%|                                                  | 0/7 [00:15<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  14%|######                                    | 1/7 [00:15<01:31, 15.30s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:44:18,350]\u001b[0m Trial 0 finished with value: 6875.0986807726895 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  14%|######                                    | 1/7 [00:15<01:31, 15.30s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  14%|######                                    | 1/7 [00:29<01:31, 15.30s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  29%|############                              | 2/7 [00:29<01:14, 14.85s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:44:32,149]\u001b[0m Trial 1 finished with value: 6993.8951373562795 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  29%|############                              | 2/7 [00:29<01:14, 14.85s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  29%|############                              | 2/7 [00:42<01:14, 14.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  43%|##################                        | 3/7 [00:42<00:57, 14.48s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:44:45,757]\u001b[0m Trial 2 finished with value: 6926.546598620022 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  43%|##################                        | 3/7 [00:42<00:57, 14.48s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  43%|##################                        | 3/7 [00:56<00:57, 14.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  57%|########################                  | 4/7 [00:56<00:42, 14.20s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:44:59,296]\u001b[0m Trial 3 finished with value: 6994.055960042684 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  57%|########################                  | 4/7 [00:56<00:42, 14.20s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  57%|########################                  | 4/7 [01:09<00:42, 14.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  71%|##############################            | 5/7 [01:09<00:27, 13.92s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:45:12,564]\u001b[0m Trial 4 finished with value: 6955.545536562771 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  71%|##############################            | 5/7 [01:09<00:27, 13.92s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  71%|##############################            | 5/7 [01:24<00:27, 13.92s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  86%|####################################      | 6/7 [01:24<00:14, 14.14s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:45:27,217]\u001b[0m Trial 5 finished with value: 6923.185356260914 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  86%|####################################      | 6/7 [01:24<00:14, 14.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681:  86%|####################################      | 6/7 [01:37<00:14, 14.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6875.098681: 100%|##########################################| 7/7 [01:37<00:00, 13.75s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:45:40,047]\u001b[0m Trial 6 finished with value: 6978.33756393288 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 6875.0986807726895.\u001b[0m\n",
      "feature_fraction, val_score: 6875.098681: 100%|##########################################| 7/7 [01:37<00:00, 13.86s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6875.098681:   0%|                                                       | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:   0%|                                                       | 0/20 [00:23<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:   5%|##3                                            | 1/20 [00:23<07:18, 23.06s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:46:03,134]\u001b[0m Trial 7 finished with value: 6595.335402914369 and parameters: {'num_leaves': 136}. Best is trial 7 with value: 6595.335402914369.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:   5%|##3                                            | 1/20 [00:23<07:18, 23.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:   5%|##3                                            | 1/20 [00:39<07:18, 23.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  10%|####7                                          | 2/20 [00:39<06:21, 21.18s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:46:19,916]\u001b[0m Trial 8 finished with value: 6818.487287226429 and parameters: {'num_leaves': 56}. Best is trial 7 with value: 6595.335402914369.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  10%|####7                                          | 2/20 [00:39<06:21, 21.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  10%|####7                                          | 2/20 [00:58<06:21, 21.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  15%|#######                                        | 3/20 [00:58<05:47, 20.44s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:46:38,653]\u001b[0m Trial 9 finished with value: 6704.8634495761 and parameters: {'num_leaves': 72}. Best is trial 7 with value: 6595.335402914369.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  15%|#######                                        | 3/20 [00:58<05:47, 20.44s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  15%|#######                                        | 3/20 [01:15<05:47, 20.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  20%|#########4                                     | 4/20 [01:15<05:11, 19.47s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:46:55,862]\u001b[0m Trial 10 finished with value: 6760.120890481871 and parameters: {'num_leaves': 50}. Best is trial 7 with value: 6595.335402914369.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6595.335403:  20%|#########4                                     | 4/20 [01:15<05:11, 19.47s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  20%|#########4                                     | 4/20 [01:42<05:11, 19.47s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  25%|###########7                                   | 5/20 [01:42<05:26, 21.74s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:47:22,903]\u001b[0m Trial 11 finished with value: 6449.043545106157 and parameters: {'num_leaves': 154}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  25%|###########7                                   | 5/20 [01:42<05:26, 21.74s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  25%|###########7                                   | 5/20 [01:59<05:26, 21.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  30%|##############1                                | 6/20 [01:59<04:44, 20.34s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:47:39,969]\u001b[0m Trial 12 finished with value: 6815.272389946455 and parameters: {'num_leaves': 51}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  30%|##############1                                | 6/20 [01:59<04:44, 20.34s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  30%|##############1                                | 6/20 [02:21<04:44, 20.34s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  35%|################4                              | 7/20 [02:21<04:31, 20.86s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:48:02,044]\u001b[0m Trial 13 finished with value: 6597.743315625649 and parameters: {'num_leaves': 108}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  35%|################4                              | 7/20 [02:21<04:31, 20.86s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  35%|################4                              | 7/20 [02:42<04:31, 20.86s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  40%|##################8                            | 8/20 [02:42<04:10, 20.85s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:48:22,858]\u001b[0m Trial 14 finished with value: 6679.1133955577925 and parameters: {'num_leaves': 109}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  40%|##################8                            | 8/20 [02:42<04:10, 20.85s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  40%|##################8                            | 8/20 [03:01<04:10, 20.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  45%|#####################1                         | 9/20 [03:01<03:41, 20.14s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:48:41,342]\u001b[0m Trial 15 finished with value: 6731.8181302941175 and parameters: {'num_leaves': 68}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  45%|#####################1                         | 9/20 [03:01<03:41, 20.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  45%|#####################1                         | 9/20 [03:28<03:41, 20.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  50%|#######################                       | 10/20 [03:28<03:41, 22.18s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:49:08,278]\u001b[0m Trial 16 finished with value: 6544.741231275497 and parameters: {'num_leaves': 188}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  50%|#######################                       | 10/20 [03:28<03:41, 22.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  50%|#######################                       | 10/20 [03:58<03:41, 22.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  55%|#########################3                    | 11/20 [03:58<03:42, 24.70s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:49:38,861]\u001b[0m Trial 17 finished with value: 6465.143910108256 and parameters: {'num_leaves': 244}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  55%|#########################3                    | 11/20 [03:58<03:42, 24.70s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  55%|#########################3                    | 11/20 [04:28<03:42, 24.70s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  60%|###########################6                  | 12/20 [04:28<03:30, 26.28s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:50:08,822]\u001b[0m Trial 18 finished with value: 6515.018019400732 and parameters: {'num_leaves': 238}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  60%|###########################6                  | 12/20 [04:28<03:30, 26.28s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  60%|###########################6                  | 12/20 [04:58<03:30, 26.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  65%|#############################9                | 13/20 [04:58<03:11, 27.40s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:50:38,852]\u001b[0m Trial 19 finished with value: 6515.018019400732 and parameters: {'num_leaves': 238}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  65%|#############################9                | 13/20 [04:58<03:11, 27.40s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  65%|#############################9                | 13/20 [05:25<03:11, 27.40s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  70%|################################1             | 14/20 [05:25<02:42, 27.05s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:51:05,093]\u001b[0m Trial 20 finished with value: 6533.1215151846445 and parameters: {'num_leaves': 183}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  70%|################################1             | 14/20 [05:25<02:42, 27.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  70%|################################1             | 14/20 [05:53<02:42, 27.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  75%|##################################5           | 15/20 [05:53<02:17, 27.52s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:51:33,692]\u001b[0m Trial 21 finished with value: 6467.38287901846 and parameters: {'num_leaves': 191}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  75%|##################################5           | 15/20 [05:53<02:17, 27.52s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  75%|##################################5           | 15/20 [06:08<02:17, 27.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  80%|####################################8         | 16/20 [06:08<01:35, 23.77s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:51:48,728]\u001b[0m Trial 22 finished with value: 7310.671416472294 and parameters: {'num_leaves': 7}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  80%|####################################8         | 16/20 [06:08<01:35, 23.77s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  80%|####################################8         | 16/20 [06:35<01:35, 23.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  85%|#######################################1      | 17/20 [06:35<01:14, 24.75s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:52:15,770]\u001b[0m Trial 23 finished with value: 6449.043545106157 and parameters: {'num_leaves': 154}. Best is trial 11 with value: 6449.043545106157.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  85%|#######################################1      | 17/20 [06:35<01:14, 24.75s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  85%|#######################################1      | 17/20 [07:01<01:14, 24.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  90%|#########################################4    | 18/20 [07:01<00:50, 25.17s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:52:41,908]\u001b[0m Trial 24 finished with value: 6449.0435451061485 and parameters: {'num_leaves': 154}. Best is trial 24 with value: 6449.0435451061485.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  90%|#########################################4    | 18/20 [07:01<00:50, 25.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  90%|#########################################4    | 18/20 [07:27<00:50, 25.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  95%|###########################################6  | 19/20 [07:27<00:25, 25.38s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:53:07,798]\u001b[0m Trial 25 finished with value: 6521.958252708921 and parameters: {'num_leaves': 160}. Best is trial 24 with value: 6449.0435451061485.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  95%|###########################################6  | 19/20 [07:27<00:25, 25.38s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545:  95%|###########################################6  | 19/20 [07:55<00:25, 25.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6449.043545: 100%|##############################################| 20/20 [07:55<00:00, 26.22s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:53:35,972]\u001b[0m Trial 26 finished with value: 6499.643518364667 and parameters: {'num_leaves': 213}. Best is trial 24 with value: 6449.0435451061485.\u001b[0m\n",
      "num_leaves, val_score: 6449.043545: 100%|##############################################| 20/20 [07:55<00:00, 23.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6449.043545:   0%|                                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 6449.043545:   0%|                                                          | 0/10 [00:29<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 6449.043545:  10%|#####                                             | 1/10 [00:29<04:23, 29.22s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:54:05,248]\u001b[0m Trial 27 finished with value: 6613.12773897527 and parameters: {'bagging_fraction': 0.8142503624645774, 'bagging_freq': 6}. Best is trial 27 with value: 6613.12773897527.\u001b[0m\n",
      "bagging, val_score: 6449.043545:  10%|#####                                             | 1/10 [00:29<04:23, 29.25s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'regression', 'metric': 'l1', 'boosting': 'gbdt', 'verbosity': 0, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 154, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100}\n",
      "Mês 6 - Error 5473.94576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 16:54:06,134]\u001b[0m A new study created in memory with name: no-name-8d951e13-a687-44a8-b777-de29f80ebc5d\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AC:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 28, 29, 31, 33, 35, 36, 37, 38, 43]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6795.740562:   0%|                                                  | 0/7 [00:14<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6795.740562:  14%|######                                    | 1/7 [00:14<01:28, 14.68s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:54:20,842]\u001b[0m Trial 0 finished with value: 6795.74056243209 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 6795.74056243209.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6795.740562:  14%|######                                    | 1/7 [00:14<01:28, 14.68s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  14%|######                                    | 1/7 [00:56<01:28, 14.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  29%|############                              | 2/7 [00:56<01:53, 22.71s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:55:02,295]\u001b[0m Trial 1 finished with value: 6366.785414380098 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 6366.785414380098.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  29%|############                              | 2/7 [00:56<01:53, 22.71s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  29%|############                              | 2/7 [01:32<01:53, 22.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  43%|##################                        | 3/7 [01:32<01:47, 26.89s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:55:38,936]\u001b[0m Trial 2 finished with value: 6398.56477159571 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 6366.785414380098.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  43%|##################                        | 3/7 [01:32<01:47, 26.89s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  43%|##################                        | 3/7 [01:50<01:47, 26.89s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  57%|########################                  | 4/7 [01:50<01:12, 24.17s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:55:56,745]\u001b[0m Trial 3 finished with value: 6718.882725634915 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 6366.785414380098.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  57%|########################                  | 4/7 [01:50<01:12, 24.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  57%|########################                  | 4/7 [02:16<01:12, 24.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  71%|##############################            | 5/7 [02:16<00:49, 24.77s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:56:22,932]\u001b[0m Trial 4 finished with value: 6561.832816614491 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 6366.785414380098.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6366.785414:  71%|##############################            | 5/7 [02:16<00:49, 24.77s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6203.283928:  71%|##############################            | 5/7 [03:15<00:49, 24.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6203.283928:  86%|####################################      | 6/7 [03:15<00:34, 34.92s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:57:21,529]\u001b[0m Trial 5 finished with value: 6203.283928015915 and parameters: {'feature_fraction': 0.4}. Best is trial 5 with value: 6203.283928015915.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6203.283928:  86%|####################################      | 6/7 [03:15<00:34, 34.92s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6203.283928:  86%|####################################      | 6/7 [03:31<00:34, 34.92s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 6203.283928: 100%|##########################################| 7/7 [03:31<00:00, 29.41s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:57:38,062]\u001b[0m Trial 6 finished with value: 6822.606281789567 and parameters: {'feature_fraction': 0.5}. Best is trial 5 with value: 6203.283928015915.\u001b[0m\n",
      "feature_fraction, val_score: 6203.283928: 100%|##########################################| 7/7 [03:31<00:00, 30.28s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:   0%|                                                       | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:   0%|                                                       | 0/20 [00:19<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:   5%|##3                                            | 1/20 [00:19<06:14, 19.72s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:57:57,805]\u001b[0m Trial 7 finished with value: 6699.699325216037 and parameters: {'num_leaves': 22}. Best is trial 7 with value: 6699.699325216037.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:   5%|##3                                            | 1/20 [00:19<06:14, 19.72s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:   5%|##3                                            | 1/20 [00:43<06:14, 19.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  10%|####7                                          | 2/20 [00:43<06:18, 21.04s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:58:21,921]\u001b[0m Trial 8 finished with value: 6367.4338118409005 and parameters: {'num_leaves': 178}. Best is trial 8 with value: 6367.4338118409005.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  10%|####7                                          | 2/20 [00:43<06:18, 21.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  10%|####7                                          | 2/20 [01:03<06:18, 21.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  15%|#######                                        | 3/20 [01:03<05:48, 20.51s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:58:41,216]\u001b[0m Trial 9 finished with value: 6430.29384151485 and parameters: {'num_leaves': 169}. Best is trial 8 with value: 6367.4338118409005.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  15%|#######                                        | 3/20 [01:03<05:48, 20.51s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  15%|#######                                        | 3/20 [01:24<05:48, 20.51s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  20%|#########4                                     | 4/20 [01:24<05:33, 20.85s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:59:02,844]\u001b[0m Trial 10 finished with value: 6420.688223555769 and parameters: {'num_leaves': 186}. Best is trial 8 with value: 6367.4338118409005.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  20%|#########4                                     | 4/20 [01:24<05:33, 20.85s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  20%|#########4                                     | 4/20 [01:47<05:33, 20.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  25%|###########7                                   | 5/20 [01:47<05:20, 21.36s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:59:25,396]\u001b[0m Trial 11 finished with value: 6401.226404361921 and parameters: {'num_leaves': 171}. Best is trial 8 with value: 6367.4338118409005.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  25%|###########7                                   | 5/20 [01:47<05:20, 21.36s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  25%|###########7                                   | 5/20 [02:08<05:20, 21.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  30%|##############1                                | 6/20 [02:08<04:57, 21.27s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 16:59:46,455]\u001b[0m Trial 12 finished with value: 6411.940923437142 and parameters: {'num_leaves': 144}. Best is trial 8 with value: 6367.4338118409005.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  30%|##############1                                | 6/20 [02:08<04:57, 21.27s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  30%|##############1                                | 6/20 [02:27<04:57, 21.27s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  35%|################4                              | 7/20 [02:27<04:29, 20.76s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:00:06,032]\u001b[0m Trial 13 finished with value: 6488.452353122846 and parameters: {'num_leaves': 113}. Best is trial 8 with value: 6367.4338118409005.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  35%|################4                              | 7/20 [02:27<04:29, 20.76s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  35%|################4                              | 7/20 [02:49<04:29, 20.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  40%|##################8                            | 8/20 [02:49<04:11, 20.98s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:00:27,511]\u001b[0m Trial 14 finished with value: 6359.74578686096 and parameters: {'num_leaves': 231}. Best is trial 14 with value: 6359.74578686096.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  40%|##################8                            | 8/20 [02:49<04:11, 20.98s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  40%|##################8                            | 8/20 [03:05<04:11, 20.98s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  45%|#####################1                         | 9/20 [03:05<03:36, 19.65s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:00:44,055]\u001b[0m Trial 15 finished with value: 6647.195891773432 and parameters: {'num_leaves': 73}. Best is trial 14 with value: 6359.74578686096.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  45%|#####################1                         | 9/20 [03:05<03:36, 19.65s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  45%|#####################1                         | 9/20 [03:23<03:36, 19.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  50%|#######################                       | 10/20 [03:23<03:11, 19.12s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:01:01,951]\u001b[0m Trial 16 finished with value: 6591.401322290643 and parameters: {'num_leaves': 64}. Best is trial 14 with value: 6359.74578686096.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  50%|#######################                       | 10/20 [03:23<03:11, 19.12s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  50%|#######################                       | 10/20 [03:49<03:11, 19.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  55%|#########################3                    | 11/20 [03:49<03:09, 21.00s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:01:27,347]\u001b[0m Trial 17 finished with value: 6280.849458515403 and parameters: {'num_leaves': 240}. Best is trial 17 with value: 6280.849458515403.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  55%|#########################3                    | 11/20 [03:49<03:09, 21.00s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  55%|#########################3                    | 11/20 [04:14<03:09, 21.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  60%|###########################6                  | 12/20 [04:14<02:57, 22.14s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:01:52,127]\u001b[0m Trial 18 finished with value: 6316.371249965751 and parameters: {'num_leaves': 256}. Best is trial 17 with value: 6280.849458515403.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  60%|###########################6                  | 12/20 [04:14<02:57, 22.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  60%|###########################6                  | 12/20 [04:38<02:57, 22.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  65%|#############################9                | 13/20 [04:38<02:40, 22.93s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:02:16,904]\u001b[0m Trial 19 finished with value: 6316.371249965751 and parameters: {'num_leaves': 256}. Best is trial 17 with value: 6280.849458515403.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  65%|#############################9                | 13/20 [04:38<02:40, 22.93s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  65%|#############################9                | 13/20 [05:04<02:40, 22.93s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  70%|################################1             | 14/20 [05:04<02:22, 23.74s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:02:42,538]\u001b[0m Trial 20 finished with value: 6330.515147789899 and parameters: {'num_leaves': 255}. Best is trial 17 with value: 6280.849458515403.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  70%|################################1             | 14/20 [05:04<02:22, 23.74s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  70%|################################1             | 14/20 [05:28<02:22, 23.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  75%|##################################5           | 15/20 [05:28<01:59, 23.80s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:03:06,494]\u001b[0m Trial 21 finished with value: 6343.565666374691 and parameters: {'num_leaves': 212}. Best is trial 17 with value: 6280.849458515403.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  75%|##################################5           | 15/20 [05:28<01:59, 23.80s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  75%|##################################5           | 15/20 [05:51<01:59, 23.80s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  80%|####################################8         | 16/20 [05:51<01:34, 23.70s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:03:29,949]\u001b[0m Trial 22 finished with value: 6365.716878140924 and parameters: {'num_leaves': 227}. Best is trial 17 with value: 6280.849458515403.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  80%|####################################8         | 16/20 [05:51<01:34, 23.70s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  80%|####################################8         | 16/20 [06:17<01:34, 23.70s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  85%|#######################################1      | 17/20 [06:17<01:12, 24.18s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:03:55,248]\u001b[0m Trial 23 finished with value: 6276.1895421138015 and parameters: {'num_leaves': 254}. Best is trial 23 with value: 6276.1895421138015.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  85%|#######################################1      | 17/20 [06:17<01:12, 24.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  85%|#######################################1      | 17/20 [06:40<01:12, 24.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 6203.283928:  90%|#########################################4    | 18/20 [06:40<00:47, 23.79s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-04-05 17:04:18,131]\u001b[0m Trial 24 finished with value: 6386.834751302641 and parameters: {'num_leaves': 209}. Best is trial 23 with value: 6276.1895421138015.\u001b[0m\n",
      "num_leaves, val_score: 6203.283928:  90%|#########################################4    | 18/20 [06:40<00:44, 22.23s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'regression', 'metric': 'l1', 'boosting': 'gbdt', 'verbosity': 0, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 31, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100}\n",
      "Mês 7 - Error 5951.85612\n",
      "Mean Error = 6624.43354\n"
     ]
    }
   ],
   "source": [
    "#### LightGBM\n",
    "\n",
    "# HyperOPT c/ Optuna \n",
    "\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):\n",
    "    \n",
    "    train = df_train[df_train['mes_referencia'] < np.datetime64(f'2020-0{mes}')]\n",
    "    \n",
    "    val = df_train[(df_train['Ano'] == 2020) & (df_train['Mês'] == mes)]\n",
    "    \n",
    "    X_train, X_test = train.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1),\n",
    "                      val.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1)\n",
    "        \n",
    "    y_train, y_test = train['TPV_mensal'].values, val['TPV_mensal'].values\n",
    "    \n",
    "    # Separa features categóricas -> LGBM lida bem com NaNs e com elas\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=y_train,\n",
    "                             categorical_feature = ['MCC', 'MacroClassificacao',\n",
    "                                                    'sub_segmento', 'persona', 'porte',\n",
    "                                                    'tipo_documento', 'Estado', 'StoneCreatedDate',\n",
    "                                                    'Região'])\n",
    "    \n",
    "    test_data = lgb.Dataset(X_test,\n",
    "                            label=y_test,\n",
    "                            reference=train_data)\n",
    "    \n",
    "    # Hiperparametros Fixos\n",
    "    \n",
    "    params = {'objective': 'regression',\n",
    "              'metric': 'mae',\n",
    "              'boosting':'gbdt',\n",
    "              'verbosity': 0}\n",
    "    \n",
    "    # Instancia e Treina o Modelo\n",
    "    model_lgbm = lgb.train(params, train_data,                     \n",
    "                           valid_sets = [train_data, test_data],\n",
    "                           valid_names=['valid'],\n",
    "                           verbose_eval = 0,\n",
    "                           early_stopping_rounds=100,\n",
    "                           time_budget = 600)\n",
    "    \n",
    "    \n",
    "    best_params = model_lgbm.params\n",
    "    \n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    pred = model_lgbm.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(y_test, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 17:23:52,577]\u001b[0m A new study created in memory with name: no-name-83d7c15c-88b6-4d6f-9771-dd9be568e108\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.189563\n",
      "0:\tlearn: 61158.4987531\ttest: 27851.5306446\tbest: 27851.5306446 (0)\ttotal: 181ms\tremaining: 3m 1s\n",
      "1:\tlearn: 59642.5352068\ttest: 25647.0414020\tbest: 25647.0414020 (1)\ttotal: 357ms\tremaining: 2m 58s\n",
      "2:\tlearn: 59642.5351882\ttest: 25647.1494233\tbest: 25647.0414020 (1)\ttotal: 446ms\tremaining: 2m 28s\n",
      "3:\tlearn: 57966.6247354\ttest: 24169.0327641\tbest: 24169.0327641 (3)\ttotal: 625ms\tremaining: 2m 35s\n",
      "4:\tlearn: 55999.5017188\ttest: 22115.5770447\tbest: 22115.5770447 (4)\ttotal: 802ms\tremaining: 2m 39s\n",
      "5:\tlearn: 54409.0433412\ttest: 20739.6031920\tbest: 20739.6031920 (5)\ttotal: 979ms\tremaining: 2m 42s\n",
      "6:\tlearn: 52810.4119012\ttest: 20504.4767586\tbest: 20504.4767586 (6)\ttotal: 1.16s\tremaining: 2m 44s\n",
      "7:\tlearn: 52450.9201801\ttest: 20151.8330512\tbest: 20151.8330512 (7)\ttotal: 1.26s\tremaining: 2m 36s\n",
      "8:\tlearn: 52282.1140452\ttest: 20224.8675437\tbest: 20151.8330512 (7)\ttotal: 1.36s\tremaining: 2m 29s\n",
      "9:\tlearn: 51838.0093729\ttest: 20038.1142248\tbest: 20038.1142248 (9)\ttotal: 1.54s\tremaining: 2m 32s\n",
      "10:\tlearn: 51073.8937016\ttest: 19814.8853848\tbest: 19814.8853848 (10)\ttotal: 1.72s\tremaining: 2m 34s\n",
      "11:\tlearn: 50093.1392171\ttest: 19766.8830449\tbest: 19766.8830449 (11)\ttotal: 1.92s\tremaining: 2m 38s\n",
      "12:\tlearn: 49481.0130307\ttest: 19919.1997774\tbest: 19766.8830449 (11)\ttotal: 2.11s\tremaining: 2m 40s\n",
      "13:\tlearn: 48908.1764696\ttest: 19666.8054845\tbest: 19666.8054845 (13)\ttotal: 2.3s\tremaining: 2m 41s\n",
      "14:\tlearn: 48636.5425379\ttest: 19605.3081842\tbest: 19605.3081842 (14)\ttotal: 2.52s\tremaining: 2m 45s\n",
      "15:\tlearn: 48009.4511670\ttest: 19797.5822081\tbest: 19605.3081842 (14)\ttotal: 2.71s\tremaining: 2m 46s\n",
      "16:\tlearn: 47943.5029577\ttest: 19927.5863397\tbest: 19605.3081842 (14)\ttotal: 2.89s\tremaining: 2m 47s\n",
      "17:\tlearn: 47556.1510156\ttest: 20030.3382180\tbest: 19605.3081842 (14)\ttotal: 3.07s\tremaining: 2m 47s\n",
      "18:\tlearn: 46964.3143029\ttest: 20527.5678698\tbest: 19605.3081842 (14)\ttotal: 3.26s\tremaining: 2m 48s\n",
      "19:\tlearn: 46721.6824554\ttest: 20375.6701460\tbest: 19605.3081842 (14)\ttotal: 3.46s\tremaining: 2m 49s\n",
      "20:\tlearn: 46402.8038892\ttest: 20692.7979133\tbest: 19605.3081842 (14)\ttotal: 3.62s\tremaining: 2m 48s\n",
      "21:\tlearn: 46090.3998567\ttest: 20659.9724455\tbest: 19605.3081842 (14)\ttotal: 3.82s\tremaining: 2m 49s\n",
      "22:\tlearn: 45358.8186690\ttest: 20697.8847734\tbest: 19605.3081842 (14)\ttotal: 3.98s\tremaining: 2m 49s\n",
      "23:\tlearn: 44774.6288845\ttest: 21183.9752777\tbest: 19605.3081842 (14)\ttotal: 4.17s\tremaining: 2m 49s\n",
      "24:\tlearn: 44674.3940276\ttest: 21119.1041109\tbest: 19605.3081842 (14)\ttotal: 4.34s\tremaining: 2m 49s\n",
      "25:\tlearn: 44571.0427707\ttest: 21072.2022212\tbest: 19605.3081842 (14)\ttotal: 4.53s\tremaining: 2m 49s\n",
      "26:\tlearn: 44192.2290402\ttest: 21059.6979298\tbest: 19605.3081842 (14)\ttotal: 4.72s\tremaining: 2m 50s\n",
      "27:\tlearn: 43911.2655566\ttest: 21136.8175097\tbest: 19605.3081842 (14)\ttotal: 4.91s\tremaining: 2m 50s\n",
      "28:\tlearn: 43810.2091245\ttest: 21074.2930520\tbest: 19605.3081842 (14)\ttotal: 5.11s\tremaining: 2m 51s\n",
      "29:\tlearn: 43734.3042487\ttest: 21063.1449019\tbest: 19605.3081842 (14)\ttotal: 5.31s\tremaining: 2m 51s\n",
      "30:\tlearn: 43644.6665443\ttest: 21067.3244580\tbest: 19605.3081842 (14)\ttotal: 5.49s\tremaining: 2m 51s\n",
      "31:\tlearn: 43471.3190162\ttest: 21035.4639535\tbest: 19605.3081842 (14)\ttotal: 5.68s\tremaining: 2m 51s\n",
      "32:\tlearn: 43194.2899878\ttest: 21102.2519502\tbest: 19605.3081842 (14)\ttotal: 5.87s\tremaining: 2m 51s\n",
      "33:\tlearn: 43185.6820938\ttest: 21080.5086652\tbest: 19605.3081842 (14)\ttotal: 6.06s\tremaining: 2m 52s\n",
      "34:\tlearn: 43145.4255217\ttest: 21040.7069593\tbest: 19605.3081842 (14)\ttotal: 6.24s\tremaining: 2m 52s\n",
      "35:\tlearn: 43131.6008631\ttest: 20944.0014662\tbest: 19605.3081842 (14)\ttotal: 6.45s\tremaining: 2m 52s\n",
      "36:\tlearn: 43096.7899204\ttest: 20970.7547789\tbest: 19605.3081842 (14)\ttotal: 6.61s\tremaining: 2m 51s\n",
      "37:\tlearn: 42732.4017740\ttest: 21041.5355121\tbest: 19605.3081842 (14)\ttotal: 6.81s\tremaining: 2m 52s\n",
      "38:\tlearn: 42675.9492029\ttest: 21074.8995336\tbest: 19605.3081842 (14)\ttotal: 6.99s\tremaining: 2m 52s\n",
      "39:\tlearn: 42666.6791949\ttest: 21081.0245343\tbest: 19605.3081842 (14)\ttotal: 7.09s\tremaining: 2m 50s\n",
      "40:\tlearn: 42666.3245289\ttest: 21080.9380474\tbest: 19605.3081842 (14)\ttotal: 7.2s\tremaining: 2m 48s\n",
      "41:\tlearn: 42581.7070188\ttest: 21037.4404637\tbest: 19605.3081842 (14)\ttotal: 7.39s\tremaining: 2m 48s\n",
      "42:\tlearn: 42148.2620160\ttest: 21365.8067550\tbest: 19605.3081842 (14)\ttotal: 7.6s\tremaining: 2m 49s\n",
      "43:\tlearn: 42112.9032463\ttest: 21368.5535809\tbest: 19605.3081842 (14)\ttotal: 7.79s\tremaining: 2m 49s\n",
      "44:\tlearn: 41677.1098446\ttest: 21690.2197551\tbest: 19605.3081842 (14)\ttotal: 7.96s\tremaining: 2m 49s\n",
      "45:\tlearn: 41533.6986366\ttest: 21744.0699947\tbest: 19605.3081842 (14)\ttotal: 8.14s\tremaining: 2m 48s\n",
      "46:\tlearn: 41495.1047631\ttest: 21704.9213767\tbest: 19605.3081842 (14)\ttotal: 8.33s\tremaining: 2m 48s\n",
      "47:\tlearn: 41405.7712858\ttest: 21786.8602277\tbest: 19605.3081842 (14)\ttotal: 8.5s\tremaining: 2m 48s\n",
      "48:\tlearn: 41255.2939956\ttest: 22024.8797480\tbest: 19605.3081842 (14)\ttotal: 8.68s\tremaining: 2m 48s\n",
      "49:\tlearn: 41048.4666553\ttest: 22305.7108035\tbest: 19605.3081842 (14)\ttotal: 8.87s\tremaining: 2m 48s\n",
      "50:\tlearn: 40960.2497703\ttest: 22368.5357238\tbest: 19605.3081842 (14)\ttotal: 9.08s\tremaining: 2m 48s\n",
      "51:\tlearn: 40929.7617988\ttest: 22327.6509743\tbest: 19605.3081842 (14)\ttotal: 9.26s\tremaining: 2m 48s\n",
      "52:\tlearn: 40906.8308429\ttest: 22316.1090406\tbest: 19605.3081842 (14)\ttotal: 9.43s\tremaining: 2m 48s\n",
      "53:\tlearn: 40863.8519415\ttest: 22323.5335496\tbest: 19605.3081842 (14)\ttotal: 9.64s\tremaining: 2m 48s\n",
      "54:\tlearn: 40844.5503215\ttest: 22320.8446741\tbest: 19605.3081842 (14)\ttotal: 9.82s\tremaining: 2m 48s\n",
      "55:\tlearn: 40832.3092351\ttest: 22287.2474922\tbest: 19605.3081842 (14)\ttotal: 9.99s\tremaining: 2m 48s\n",
      "56:\tlearn: 40639.7144352\ttest: 22214.5265998\tbest: 19605.3081842 (14)\ttotal: 10.2s\tremaining: 2m 48s\n",
      "57:\tlearn: 40626.7544235\ttest: 22242.8431898\tbest: 19605.3081842 (14)\ttotal: 10.3s\tremaining: 2m 47s\n",
      "58:\tlearn: 40580.9246139\ttest: 22217.7320289\tbest: 19605.3081842 (14)\ttotal: 10.5s\tremaining: 2m 47s\n",
      "59:\tlearn: 40567.0230247\ttest: 22211.2304521\tbest: 19605.3081842 (14)\ttotal: 10.7s\tremaining: 2m 46s\n",
      "60:\tlearn: 39672.4291058\ttest: 22185.6533318\tbest: 19605.3081842 (14)\ttotal: 10.8s\tremaining: 2m 46s\n",
      "61:\tlearn: 39661.1934581\ttest: 22198.6808857\tbest: 19605.3081842 (14)\ttotal: 11s\tremaining: 2m 45s\n",
      "62:\tlearn: 39587.7052985\ttest: 22127.0739539\tbest: 19605.3081842 (14)\ttotal: 11.1s\tremaining: 2m 45s\n",
      "63:\tlearn: 39546.9674850\ttest: 22176.0623699\tbest: 19605.3081842 (14)\ttotal: 11.3s\tremaining: 2m 45s\n",
      "64:\tlearn: 39543.7653875\ttest: 22167.8159429\tbest: 19605.3081842 (14)\ttotal: 11.5s\tremaining: 2m 44s\n",
      "65:\tlearn: 39517.0249518\ttest: 22150.6055211\tbest: 19605.3081842 (14)\ttotal: 11.7s\tremaining: 2m 44s\n",
      "66:\tlearn: 39458.3660352\ttest: 22205.7408687\tbest: 19605.3081842 (14)\ttotal: 11.8s\tremaining: 2m 44s\n",
      "67:\tlearn: 39431.7078742\ttest: 22228.1414401\tbest: 19605.3081842 (14)\ttotal: 12s\tremaining: 2m 45s\n",
      "68:\tlearn: 39349.8009501\ttest: 22181.2533594\tbest: 19605.3081842 (14)\ttotal: 12.2s\tremaining: 2m 45s\n",
      "69:\tlearn: 39206.3297013\ttest: 22256.0800745\tbest: 19605.3081842 (14)\ttotal: 12.4s\tremaining: 2m 44s\n",
      "70:\tlearn: 39118.4474340\ttest: 22362.4521951\tbest: 19605.3081842 (14)\ttotal: 12.6s\tremaining: 2m 44s\n",
      "71:\tlearn: 39109.1205997\ttest: 22358.6529945\tbest: 19605.3081842 (14)\ttotal: 12.8s\tremaining: 2m 44s\n",
      "72:\tlearn: 39053.9153004\ttest: 22384.7466675\tbest: 19605.3081842 (14)\ttotal: 12.9s\tremaining: 2m 44s\n",
      "73:\tlearn: 38948.7421326\ttest: 22425.5863516\tbest: 19605.3081842 (14)\ttotal: 13.1s\tremaining: 2m 44s\n",
      "74:\tlearn: 38870.1456591\ttest: 22455.6806097\tbest: 19605.3081842 (14)\ttotal: 13.3s\tremaining: 2m 44s\n",
      "75:\tlearn: 38858.8146221\ttest: 22430.0448743\tbest: 19605.3081842 (14)\ttotal: 13.5s\tremaining: 2m 43s\n",
      "76:\tlearn: 38854.9074674\ttest: 22452.5241308\tbest: 19605.3081842 (14)\ttotal: 13.6s\tremaining: 2m 43s\n",
      "77:\tlearn: 38655.0905352\ttest: 22663.6514503\tbest: 19605.3081842 (14)\ttotal: 13.8s\tremaining: 2m 43s\n",
      "78:\tlearn: 38637.1497070\ttest: 22677.2867484\tbest: 19605.3081842 (14)\ttotal: 14s\tremaining: 2m 43s\n",
      "79:\tlearn: 38476.5923577\ttest: 22628.5920676\tbest: 19605.3081842 (14)\ttotal: 14.2s\tremaining: 2m 43s\n",
      "80:\tlearn: 38460.8882288\ttest: 22603.6656242\tbest: 19605.3081842 (14)\ttotal: 14.4s\tremaining: 2m 43s\n",
      "81:\tlearn: 38311.2078082\ttest: 22673.5845086\tbest: 19605.3081842 (14)\ttotal: 14.6s\tremaining: 2m 43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82:\tlearn: 38306.8211118\ttest: 22690.7517777\tbest: 19605.3081842 (14)\ttotal: 14.8s\tremaining: 2m 43s\n",
      "83:\tlearn: 38295.9776662\ttest: 22686.8089972\tbest: 19605.3081842 (14)\ttotal: 14.9s\tremaining: 2m 43s\n",
      "84:\tlearn: 38200.5573780\ttest: 22673.6417233\tbest: 19605.3081842 (14)\ttotal: 15.2s\tremaining: 2m 43s\n",
      "85:\tlearn: 38191.4948073\ttest: 22677.2378735\tbest: 19605.3081842 (14)\ttotal: 15.4s\tremaining: 2m 43s\n",
      "86:\tlearn: 38183.7166675\ttest: 22692.9964637\tbest: 19605.3081842 (14)\ttotal: 15.6s\tremaining: 2m 43s\n",
      "87:\tlearn: 38148.8118678\ttest: 22735.5504736\tbest: 19605.3081842 (14)\ttotal: 15.7s\tremaining: 2m 43s\n",
      "88:\tlearn: 38100.3198629\ttest: 22749.4750681\tbest: 19605.3081842 (14)\ttotal: 15.9s\tremaining: 2m 42s\n",
      "89:\tlearn: 38051.9007684\ttest: 22776.2028087\tbest: 19605.3081842 (14)\ttotal: 16.1s\tremaining: 2m 42s\n",
      "90:\tlearn: 37964.9068400\ttest: 22698.1410025\tbest: 19605.3081842 (14)\ttotal: 16.3s\tremaining: 2m 42s\n",
      "91:\tlearn: 37952.6314445\ttest: 22671.4202479\tbest: 19605.3081842 (14)\ttotal: 16.4s\tremaining: 2m 42s\n",
      "92:\tlearn: 37727.5832579\ttest: 22732.3281818\tbest: 19605.3081842 (14)\ttotal: 16.6s\tremaining: 2m 41s\n",
      "93:\tlearn: 37725.5824661\ttest: 22736.7658644\tbest: 19605.3081842 (14)\ttotal: 16.8s\tremaining: 2m 41s\n",
      "94:\tlearn: 37107.9769030\ttest: 22760.9514729\tbest: 19605.3081842 (14)\ttotal: 17s\tremaining: 2m 41s\n",
      "95:\tlearn: 37099.1947946\ttest: 22727.5706713\tbest: 19605.3081842 (14)\ttotal: 17.2s\tremaining: 2m 41s\n",
      "96:\tlearn: 36648.1255797\ttest: 22701.4884828\tbest: 19605.3081842 (14)\ttotal: 17.4s\tremaining: 2m 41s\n",
      "97:\tlearn: 36640.4310035\ttest: 22694.6117114\tbest: 19605.3081842 (14)\ttotal: 17.6s\tremaining: 2m 41s\n",
      "98:\tlearn: 36482.9332721\ttest: 22925.5924984\tbest: 19605.3081842 (14)\ttotal: 17.7s\tremaining: 2m 41s\n",
      "99:\tlearn: 36470.8221179\ttest: 22909.1634611\tbest: 19605.3081842 (14)\ttotal: 17.9s\tremaining: 2m 41s\n",
      "100:\tlearn: 36052.4209829\ttest: 23409.9179671\tbest: 19605.3081842 (14)\ttotal: 18.1s\tremaining: 2m 41s\n",
      "101:\tlearn: 36020.9005346\ttest: 23467.2205954\tbest: 19605.3081842 (14)\ttotal: 18.3s\tremaining: 2m 41s\n",
      "102:\tlearn: 36006.0615526\ttest: 23507.6152574\tbest: 19605.3081842 (14)\ttotal: 18.5s\tremaining: 2m 41s\n",
      "103:\tlearn: 35953.1486875\ttest: 23467.5184213\tbest: 19605.3081842 (14)\ttotal: 18.7s\tremaining: 2m 40s\n",
      "104:\tlearn: 35949.9431481\ttest: 23464.2883892\tbest: 19605.3081842 (14)\ttotal: 18.8s\tremaining: 2m 40s\n",
      "105:\tlearn: 35896.3269113\ttest: 23559.5613893\tbest: 19605.3081842 (14)\ttotal: 19s\tremaining: 2m 40s\n",
      "106:\tlearn: 35872.3199968\ttest: 23547.8250865\tbest: 19605.3081842 (14)\ttotal: 19.2s\tremaining: 2m 39s\n",
      "107:\tlearn: 35857.4644096\ttest: 23562.5683986\tbest: 19605.3081842 (14)\ttotal: 19.4s\tremaining: 2m 39s\n",
      "108:\tlearn: 35814.9114306\ttest: 23675.1898871\tbest: 19605.3081842 (14)\ttotal: 19.5s\tremaining: 2m 39s\n",
      "109:\tlearn: 35814.8960713\ttest: 23672.0443838\tbest: 19605.3081842 (14)\ttotal: 19.6s\tremaining: 2m 38s\n",
      "110:\tlearn: 35806.3611156\ttest: 23646.1335230\tbest: 19605.3081842 (14)\ttotal: 19.8s\tremaining: 2m 38s\n",
      "111:\tlearn: 35802.9062492\ttest: 23633.6761213\tbest: 19605.3081842 (14)\ttotal: 19.9s\tremaining: 2m 38s\n",
      "112:\tlearn: 35799.0086674\ttest: 23640.0098737\tbest: 19605.3081842 (14)\ttotal: 20.2s\tremaining: 2m 38s\n",
      "113:\tlearn: 35798.4945304\ttest: 23638.5602783\tbest: 19605.3081842 (14)\ttotal: 20.3s\tremaining: 2m 37s\n",
      "114:\tlearn: 35797.1127789\ttest: 23632.3532865\tbest: 19605.3081842 (14)\ttotal: 20.4s\tremaining: 2m 37s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 19605.30818\n",
      "bestIteration = 14\n",
      "\n",
      "Shrink model to first 15 iterations.\n",
      "Learning rate set to 0.192732\n",
      "0:\tlearn: 58921.5603567\ttest: 26559.8347983\tbest: 26559.8347983 (0)\ttotal: 183ms\tremaining: 3m 3s\n",
      "1:\tlearn: 56530.4057044\ttest: 24855.1230189\tbest: 24855.1230189 (1)\ttotal: 375ms\tremaining: 3m 7s\n",
      "2:\tlearn: 54294.6528416\ttest: 23123.5716700\tbest: 23123.5716700 (2)\ttotal: 563ms\tremaining: 3m 7s\n",
      "3:\tlearn: 52662.1816618\ttest: 22131.4460744\tbest: 22131.4460744 (3)\ttotal: 752ms\tremaining: 3m 7s\n",
      "4:\tlearn: 51384.3493411\ttest: 21696.7975176\tbest: 21696.7975176 (4)\ttotal: 955ms\tremaining: 3m 10s\n",
      "5:\tlearn: 50280.5291720\ttest: 21364.5968199\tbest: 21364.5968199 (5)\ttotal: 1.14s\tremaining: 3m 9s\n",
      "6:\tlearn: 48556.5050297\ttest: 21404.9048923\tbest: 21364.5968199 (5)\ttotal: 1.33s\tremaining: 3m 9s\n",
      "7:\tlearn: 48430.3328619\ttest: 21617.6586198\tbest: 21364.5968199 (5)\ttotal: 1.44s\tremaining: 2m 58s\n",
      "8:\tlearn: 47876.2793927\ttest: 21230.6116216\tbest: 21230.6116216 (8)\ttotal: 1.63s\tremaining: 2m 59s\n",
      "9:\tlearn: 47429.2571595\ttest: 21478.9946091\tbest: 21230.6116216 (8)\ttotal: 1.8s\tremaining: 2m 58s\n",
      "10:\tlearn: 47067.2528236\ttest: 21542.2284593\tbest: 21230.6116216 (8)\ttotal: 2.01s\tremaining: 3m\n",
      "11:\tlearn: 46870.4733023\ttest: 21474.5284857\tbest: 21230.6116216 (8)\ttotal: 2.19s\tremaining: 3m\n",
      "12:\tlearn: 46870.4732710\ttest: 21474.6638040\tbest: 21230.6116216 (8)\ttotal: 2.29s\tremaining: 2m 53s\n",
      "13:\tlearn: 46070.1265915\ttest: 21816.0060755\tbest: 21230.6116216 (8)\ttotal: 2.47s\tremaining: 2m 54s\n",
      "14:\tlearn: 45191.4559382\ttest: 22108.2613733\tbest: 21230.6116216 (8)\ttotal: 2.65s\tremaining: 2m 54s\n",
      "15:\tlearn: 45151.0054645\ttest: 22263.3489788\tbest: 21230.6116216 (8)\ttotal: 2.8s\tremaining: 2m 52s\n",
      "16:\tlearn: 44134.5245786\ttest: 23210.7332633\tbest: 21230.6116216 (8)\ttotal: 3.01s\tremaining: 2m 54s\n",
      "17:\tlearn: 43919.9207423\ttest: 23473.8425224\tbest: 21230.6116216 (8)\ttotal: 3.21s\tremaining: 2m 54s\n",
      "18:\tlearn: 43824.6906818\ttest: 23473.5262897\tbest: 21230.6116216 (8)\ttotal: 3.4s\tremaining: 2m 55s\n",
      "19:\tlearn: 43679.6372477\ttest: 23419.2901467\tbest: 21230.6116216 (8)\ttotal: 3.6s\tremaining: 2m 56s\n",
      "20:\tlearn: 43222.7630408\ttest: 23600.3069886\tbest: 21230.6116216 (8)\ttotal: 3.79s\tremaining: 2m 56s\n",
      "21:\tlearn: 42849.2490783\ttest: 23790.3596868\tbest: 21230.6116216 (8)\ttotal: 3.99s\tremaining: 2m 57s\n",
      "22:\tlearn: 42742.2437975\ttest: 23765.8193792\tbest: 21230.6116216 (8)\ttotal: 4.19s\tremaining: 2m 58s\n",
      "23:\tlearn: 42421.4430706\ttest: 23960.5925227\tbest: 21230.6116216 (8)\ttotal: 4.38s\tremaining: 2m 58s\n",
      "24:\tlearn: 42383.5460448\ttest: 23936.4801452\tbest: 21230.6116216 (8)\ttotal: 4.57s\tremaining: 2m 58s\n",
      "25:\tlearn: 42346.4403572\ttest: 23939.2760897\tbest: 21230.6116216 (8)\ttotal: 4.68s\tremaining: 2m 55s\n",
      "26:\tlearn: 42290.6351285\ttest: 23815.9060044\tbest: 21230.6116216 (8)\ttotal: 4.86s\tremaining: 2m 55s\n",
      "27:\tlearn: 42113.9139496\ttest: 23941.8703266\tbest: 21230.6116216 (8)\ttotal: 5.06s\tremaining: 2m 55s\n",
      "28:\tlearn: 41728.3736387\ttest: 23840.6431194\tbest: 21230.6116216 (8)\ttotal: 5.23s\tremaining: 2m 55s\n",
      "29:\tlearn: 41607.7475750\ttest: 23899.6128763\tbest: 21230.6116216 (8)\ttotal: 5.4s\tremaining: 2m 54s\n",
      "30:\tlearn: 41385.5703638\ttest: 24114.0430833\tbest: 21230.6116216 (8)\ttotal: 5.6s\tremaining: 2m 55s\n",
      "31:\tlearn: 41358.4700893\ttest: 24081.6688385\tbest: 21230.6116216 (8)\ttotal: 5.83s\tremaining: 2m 56s\n",
      "32:\tlearn: 41358.4700748\ttest: 24081.7276300\tbest: 21230.6116216 (8)\ttotal: 5.92s\tremaining: 2m 53s\n",
      "33:\tlearn: 41046.7573079\ttest: 24279.6565985\tbest: 21230.6116216 (8)\ttotal: 6.13s\tremaining: 2m 54s\n",
      "34:\tlearn: 40976.6850916\ttest: 24351.0291016\tbest: 21230.6116216 (8)\ttotal: 6.31s\tremaining: 2m 53s\n",
      "35:\tlearn: 40961.5880215\ttest: 24280.9088150\tbest: 21230.6116216 (8)\ttotal: 6.5s\tremaining: 2m 53s\n",
      "36:\tlearn: 40832.9264349\ttest: 24390.9337056\tbest: 21230.6116216 (8)\ttotal: 6.7s\tremaining: 2m 54s\n",
      "37:\tlearn: 40801.0621383\ttest: 24339.2910885\tbest: 21230.6116216 (8)\ttotal: 6.89s\tremaining: 2m 54s\n",
      "38:\tlearn: 40775.3077032\ttest: 24324.3383202\tbest: 21230.6116216 (8)\ttotal: 7.1s\tremaining: 2m 55s\n",
      "39:\tlearn: 40692.6920260\ttest: 24372.0420623\tbest: 21230.6116216 (8)\ttotal: 7.28s\tremaining: 2m 54s\n",
      "40:\tlearn: 40661.6882780\ttest: 24411.7607587\tbest: 21230.6116216 (8)\ttotal: 7.47s\tremaining: 2m 54s\n",
      "41:\tlearn: 40432.3810037\ttest: 24408.3654114\tbest: 21230.6116216 (8)\ttotal: 7.66s\tremaining: 2m 54s\n",
      "42:\tlearn: 40328.8190895\ttest: 24183.0033259\tbest: 21230.6116216 (8)\ttotal: 7.85s\tremaining: 2m 54s\n",
      "43:\tlearn: 40300.4373812\ttest: 24026.0927871\tbest: 21230.6116216 (8)\ttotal: 8.07s\tremaining: 2m 55s\n",
      "44:\tlearn: 40300.4373782\ttest: 24026.1158770\tbest: 21230.6116216 (8)\ttotal: 8.16s\tremaining: 2m 53s\n",
      "45:\tlearn: 39877.3104260\ttest: 24030.4725097\tbest: 21230.6116216 (8)\ttotal: 8.35s\tremaining: 2m 53s\n",
      "46:\tlearn: 39815.1443738\ttest: 24039.2733248\tbest: 21230.6116216 (8)\ttotal: 8.53s\tremaining: 2m 52s\n",
      "47:\tlearn: 39782.5122149\ttest: 24020.8252795\tbest: 21230.6116216 (8)\ttotal: 8.71s\tremaining: 2m 52s\n",
      "48:\tlearn: 39760.8946264\ttest: 23991.6764534\tbest: 21230.6116216 (8)\ttotal: 8.92s\tremaining: 2m 53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49:\tlearn: 39363.0679181\ttest: 24290.6831252\tbest: 21230.6116216 (8)\ttotal: 9.1s\tremaining: 2m 52s\n",
      "50:\tlearn: 39346.0815336\ttest: 24266.6853894\tbest: 21230.6116216 (8)\ttotal: 9.29s\tremaining: 2m 52s\n",
      "51:\tlearn: 39194.6239346\ttest: 24272.3853467\tbest: 21230.6116216 (8)\ttotal: 9.48s\tremaining: 2m 52s\n",
      "52:\tlearn: 39192.1746825\ttest: 24284.7483781\tbest: 21230.6116216 (8)\ttotal: 9.65s\tremaining: 2m 52s\n",
      "53:\tlearn: 39182.9417998\ttest: 24247.0800082\tbest: 21230.6116216 (8)\ttotal: 9.88s\tremaining: 2m 53s\n",
      "54:\tlearn: 39148.1210019\ttest: 24209.0119802\tbest: 21230.6116216 (8)\ttotal: 10.1s\tremaining: 2m 53s\n",
      "55:\tlearn: 39094.0606668\ttest: 24183.0242288\tbest: 21230.6116216 (8)\ttotal: 10.3s\tremaining: 2m 53s\n",
      "56:\tlearn: 39059.7858992\ttest: 24180.5551580\tbest: 21230.6116216 (8)\ttotal: 10.5s\tremaining: 2m 53s\n",
      "57:\tlearn: 38993.3487421\ttest: 24139.9901106\tbest: 21230.6116216 (8)\ttotal: 10.7s\tremaining: 2m 53s\n",
      "58:\tlearn: 38984.7987270\ttest: 24132.8815624\tbest: 21230.6116216 (8)\ttotal: 10.9s\tremaining: 2m 54s\n",
      "59:\tlearn: 38984.0550321\ttest: 24140.0351744\tbest: 21230.6116216 (8)\ttotal: 11s\tremaining: 2m 52s\n",
      "60:\tlearn: 38971.4063229\ttest: 24109.0748484\tbest: 21230.6116216 (8)\ttotal: 11.2s\tremaining: 2m 52s\n",
      "61:\tlearn: 38741.7800038\ttest: 24147.0596869\tbest: 21230.6116216 (8)\ttotal: 11.4s\tremaining: 2m 52s\n",
      "62:\tlearn: 38548.7486726\ttest: 24117.2839595\tbest: 21230.6116216 (8)\ttotal: 11.6s\tremaining: 2m 52s\n",
      "63:\tlearn: 38522.4658971\ttest: 24182.8450585\tbest: 21230.6116216 (8)\ttotal: 11.7s\tremaining: 2m 51s\n",
      "64:\tlearn: 38522.4658603\ttest: 24182.9720633\tbest: 21230.6116216 (8)\ttotal: 11.8s\tremaining: 2m 50s\n",
      "65:\tlearn: 38514.0790361\ttest: 24160.6697801\tbest: 21230.6116216 (8)\ttotal: 12s\tremaining: 2m 50s\n",
      "66:\tlearn: 38476.8715041\ttest: 24196.9335968\tbest: 21230.6116216 (8)\ttotal: 12.2s\tremaining: 2m 49s\n",
      "67:\tlearn: 38324.0659715\ttest: 24269.4659760\tbest: 21230.6116216 (8)\ttotal: 12.4s\tremaining: 2m 49s\n",
      "68:\tlearn: 38299.8974867\ttest: 24282.7436152\tbest: 21230.6116216 (8)\ttotal: 12.6s\tremaining: 2m 49s\n",
      "69:\tlearn: 38264.1029535\ttest: 24252.0903743\tbest: 21230.6116216 (8)\ttotal: 12.7s\tremaining: 2m 49s\n",
      "70:\tlearn: 38257.5605883\ttest: 24239.0178352\tbest: 21230.6116216 (8)\ttotal: 12.9s\tremaining: 2m 49s\n",
      "71:\tlearn: 38231.2924450\ttest: 24248.6043576\tbest: 21230.6116216 (8)\ttotal: 13.1s\tremaining: 2m 48s\n",
      "72:\tlearn: 38021.5383357\ttest: 24467.0069363\tbest: 21230.6116216 (8)\ttotal: 13.3s\tremaining: 2m 48s\n",
      "73:\tlearn: 37975.3951232\ttest: 24431.8195054\tbest: 21230.6116216 (8)\ttotal: 13.5s\tremaining: 2m 48s\n",
      "74:\tlearn: 37920.4257955\ttest: 24431.2553461\tbest: 21230.6116216 (8)\ttotal: 13.7s\tremaining: 2m 48s\n",
      "75:\tlearn: 37849.2394615\ttest: 24481.1193494\tbest: 21230.6116216 (8)\ttotal: 13.9s\tremaining: 2m 48s\n",
      "76:\tlearn: 37794.9994551\ttest: 24504.0553307\tbest: 21230.6116216 (8)\ttotal: 14.1s\tremaining: 2m 48s\n",
      "77:\tlearn: 37751.4144269\ttest: 24417.9603693\tbest: 21230.6116216 (8)\ttotal: 14.3s\tremaining: 2m 48s\n",
      "78:\tlearn: 37678.9805468\ttest: 24341.8582983\tbest: 21230.6116216 (8)\ttotal: 14.4s\tremaining: 2m 48s\n",
      "79:\tlearn: 37595.2207330\ttest: 24354.1563201\tbest: 21230.6116216 (8)\ttotal: 14.6s\tremaining: 2m 48s\n",
      "80:\tlearn: 37592.3127611\ttest: 24354.5871728\tbest: 21230.6116216 (8)\ttotal: 14.8s\tremaining: 2m 48s\n",
      "81:\tlearn: 37411.8079315\ttest: 24240.4443664\tbest: 21230.6116216 (8)\ttotal: 15s\tremaining: 2m 48s\n",
      "82:\tlearn: 37386.0874876\ttest: 24265.4877784\tbest: 21230.6116216 (8)\ttotal: 15.2s\tremaining: 2m 48s\n",
      "83:\tlearn: 36908.4477176\ttest: 24691.8840566\tbest: 21230.6116216 (8)\ttotal: 15.4s\tremaining: 2m 47s\n",
      "84:\tlearn: 36703.9272418\ttest: 25065.8889973\tbest: 21230.6116216 (8)\ttotal: 15.6s\tremaining: 2m 47s\n",
      "85:\tlearn: 36071.3147966\ttest: 26040.4711790\tbest: 21230.6116216 (8)\ttotal: 15.8s\tremaining: 2m 47s\n",
      "86:\tlearn: 36071.3147578\ttest: 26040.5354240\tbest: 21230.6116216 (8)\ttotal: 15.9s\tremaining: 2m 46s\n",
      "87:\tlearn: 36039.5222664\ttest: 26131.0395799\tbest: 21230.6116216 (8)\ttotal: 16.1s\tremaining: 2m 46s\n",
      "88:\tlearn: 36025.7070469\ttest: 26124.5665288\tbest: 21230.6116216 (8)\ttotal: 16.3s\tremaining: 2m 46s\n",
      "89:\tlearn: 36022.8532257\ttest: 26130.1888478\tbest: 21230.6116216 (8)\ttotal: 16.4s\tremaining: 2m 46s\n",
      "90:\tlearn: 35864.8987778\ttest: 26392.8795684\tbest: 21230.6116216 (8)\ttotal: 16.6s\tremaining: 2m 46s\n",
      "91:\tlearn: 35638.2009818\ttest: 26263.0091046\tbest: 21230.6116216 (8)\ttotal: 16.8s\tremaining: 2m 45s\n",
      "92:\tlearn: 35632.4028298\ttest: 26259.9902523\tbest: 21230.6116216 (8)\ttotal: 17s\tremaining: 2m 45s\n",
      "93:\tlearn: 35612.0538695\ttest: 26258.6729271\tbest: 21230.6116216 (8)\ttotal: 17.2s\tremaining: 2m 45s\n",
      "94:\tlearn: 35559.5208657\ttest: 26242.5466521\tbest: 21230.6116216 (8)\ttotal: 17.3s\tremaining: 2m 45s\n",
      "95:\tlearn: 35505.9530695\ttest: 26283.2108073\tbest: 21230.6116216 (8)\ttotal: 17.5s\tremaining: 2m 44s\n",
      "96:\tlearn: 35505.9530686\ttest: 26283.2201072\tbest: 21230.6116216 (8)\ttotal: 17.6s\tremaining: 2m 43s\n",
      "97:\tlearn: 35361.8566934\ttest: 26323.4774002\tbest: 21230.6116216 (8)\ttotal: 17.8s\tremaining: 2m 43s\n",
      "98:\tlearn: 35264.2706323\ttest: 26448.6768630\tbest: 21230.6116216 (8)\ttotal: 18s\tremaining: 2m 43s\n",
      "99:\tlearn: 35248.0565802\ttest: 26434.0709919\tbest: 21230.6116216 (8)\ttotal: 18.2s\tremaining: 2m 43s\n",
      "100:\tlearn: 35223.9008147\ttest: 26365.7282840\tbest: 21230.6116216 (8)\ttotal: 18.4s\tremaining: 2m 43s\n",
      "101:\tlearn: 35197.5649518\ttest: 26391.4187065\tbest: 21230.6116216 (8)\ttotal: 18.6s\tremaining: 2m 43s\n",
      "102:\tlearn: 35182.9700994\ttest: 26384.3467953\tbest: 21230.6116216 (8)\ttotal: 18.8s\tremaining: 2m 43s\n",
      "103:\tlearn: 34993.5092102\ttest: 26365.9436644\tbest: 21230.6116216 (8)\ttotal: 19s\tremaining: 2m 43s\n",
      "104:\tlearn: 34984.0879488\ttest: 26348.2676556\tbest: 21230.6116216 (8)\ttotal: 19.1s\tremaining: 2m 43s\n",
      "105:\tlearn: 34808.0900253\ttest: 26337.8885751\tbest: 21230.6116216 (8)\ttotal: 19.3s\tremaining: 2m 43s\n",
      "106:\tlearn: 34778.6285899\ttest: 26312.1518879\tbest: 21230.6116216 (8)\ttotal: 19.5s\tremaining: 2m 42s\n",
      "107:\tlearn: 34753.0082490\ttest: 26288.2942079\tbest: 21230.6116216 (8)\ttotal: 19.7s\tremaining: 2m 42s\n",
      "108:\tlearn: 34746.7114232\ttest: 26269.0481869\tbest: 21230.6116216 (8)\ttotal: 19.9s\tremaining: 2m 42s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 21230.61162\n",
      "bestIteration = 8\n",
      "\n",
      "Shrink model to first 9 iterations.\n",
      "Learning rate set to 0.195733\n",
      "0:\tlearn: 57155.6952180\ttest: 27825.2202470\tbest: 27825.2202470 (0)\ttotal: 198ms\tremaining: 3m 18s\n",
      "1:\tlearn: 55464.2399901\ttest: 26475.5823942\tbest: 26475.5823942 (1)\ttotal: 388ms\tremaining: 3m 13s\n",
      "2:\tlearn: 53424.4620158\ttest: 24292.8090945\tbest: 24292.8090945 (2)\ttotal: 588ms\tremaining: 3m 15s\n",
      "3:\tlearn: 51660.3668994\ttest: 22757.1952643\tbest: 22757.1952643 (3)\ttotal: 807ms\tremaining: 3m 20s\n",
      "4:\tlearn: 50798.7780405\ttest: 21469.7297506\tbest: 21469.7297506 (4)\ttotal: 1.01s\tremaining: 3m 20s\n",
      "5:\tlearn: 49250.2188363\ttest: 20773.3798894\tbest: 20773.3798894 (5)\ttotal: 1.22s\tremaining: 3m 21s\n",
      "6:\tlearn: 48263.0712448\ttest: 19889.5554261\tbest: 19889.5554261 (6)\ttotal: 1.42s\tremaining: 3m 20s\n",
      "7:\tlearn: 47700.2267052\ttest: 18975.4875459\tbest: 18975.4875459 (7)\ttotal: 1.63s\tremaining: 3m 22s\n",
      "8:\tlearn: 47017.3922674\ttest: 18804.1704491\tbest: 18804.1704491 (8)\ttotal: 1.85s\tremaining: 3m 23s\n",
      "9:\tlearn: 45667.2993699\ttest: 19220.3754686\tbest: 18804.1704491 (8)\ttotal: 2.06s\tremaining: 3m 23s\n",
      "10:\tlearn: 45616.4172298\ttest: 19182.2477836\tbest: 18804.1704491 (8)\ttotal: 2.17s\tremaining: 3m 14s\n",
      "11:\tlearn: 45158.0947008\ttest: 19116.2669742\tbest: 18804.1704491 (8)\ttotal: 2.38s\tremaining: 3m 16s\n",
      "12:\tlearn: 44414.0718039\ttest: 18992.0934940\tbest: 18804.1704491 (8)\ttotal: 2.6s\tremaining: 3m 17s\n",
      "13:\tlearn: 44293.5728319\ttest: 18863.3823307\tbest: 18804.1704491 (8)\ttotal: 2.79s\tremaining: 3m 16s\n",
      "14:\tlearn: 44029.7312057\ttest: 18556.4449005\tbest: 18556.4449005 (14)\ttotal: 3.01s\tremaining: 3m 17s\n",
      "15:\tlearn: 43459.2669876\ttest: 18612.4668094\tbest: 18556.4449005 (14)\ttotal: 3.21s\tremaining: 3m 17s\n",
      "16:\tlearn: 43360.2982055\ttest: 18434.3525393\tbest: 18434.3525393 (16)\ttotal: 3.4s\tremaining: 3m 16s\n",
      "17:\tlearn: 43230.8120976\ttest: 18352.7715128\tbest: 18352.7715128 (17)\ttotal: 3.6s\tremaining: 3m 16s\n",
      "18:\tlearn: 43128.1282074\ttest: 18357.7106769\tbest: 18352.7715128 (17)\ttotal: 3.78s\tremaining: 3m 15s\n",
      "19:\tlearn: 43128.1281748\ttest: 18357.6948882\tbest: 18352.7715128 (17)\ttotal: 3.88s\tremaining: 3m 10s\n",
      "20:\tlearn: 42817.1788022\ttest: 18281.2190697\tbest: 18281.2190697 (20)\ttotal: 4.09s\tremaining: 3m 10s\n",
      "21:\tlearn: 41924.8100295\ttest: 18228.5259955\tbest: 18228.5259955 (21)\ttotal: 4.29s\tremaining: 3m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:\tlearn: 41913.6955583\ttest: 18189.9907241\tbest: 18189.9907241 (22)\ttotal: 4.4s\tremaining: 3m 6s\n",
      "23:\tlearn: 41640.2177214\ttest: 18040.0728838\tbest: 18040.0728838 (23)\ttotal: 4.59s\tremaining: 3m 6s\n",
      "24:\tlearn: 41230.2002291\ttest: 17941.7606676\tbest: 17941.7606676 (24)\ttotal: 4.8s\tremaining: 3m 7s\n",
      "25:\tlearn: 41178.8847637\ttest: 17826.8124349\tbest: 17826.8124349 (25)\ttotal: 5.01s\tremaining: 3m 7s\n",
      "26:\tlearn: 41083.6675258\ttest: 17862.6896219\tbest: 17826.8124349 (25)\ttotal: 5.21s\tremaining: 3m 7s\n",
      "27:\tlearn: 41043.8012593\ttest: 17765.8484411\tbest: 17765.8484411 (27)\ttotal: 5.42s\tremaining: 3m 8s\n",
      "28:\tlearn: 40670.9198936\ttest: 17964.0253711\tbest: 17765.8484411 (27)\ttotal: 5.62s\tremaining: 3m 8s\n",
      "29:\tlearn: 40627.5942510\ttest: 17884.0593199\tbest: 17765.8484411 (27)\ttotal: 5.82s\tremaining: 3m 8s\n",
      "30:\tlearn: 40262.5073485\ttest: 17671.0834270\tbest: 17671.0834270 (30)\ttotal: 6.02s\tremaining: 3m 8s\n",
      "31:\tlearn: 40247.9307453\ttest: 17680.3127460\tbest: 17671.0834270 (30)\ttotal: 6.22s\tremaining: 3m 8s\n",
      "32:\tlearn: 40201.9570823\ttest: 17615.9067141\tbest: 17615.9067141 (32)\ttotal: 6.4s\tremaining: 3m 7s\n",
      "33:\tlearn: 39941.4506670\ttest: 17662.7219237\tbest: 17615.9067141 (32)\ttotal: 6.6s\tremaining: 3m 7s\n",
      "34:\tlearn: 39266.3803679\ttest: 18105.4527859\tbest: 17615.9067141 (32)\ttotal: 6.79s\tremaining: 3m 7s\n",
      "35:\tlearn: 39216.1074314\ttest: 18093.4742830\tbest: 17615.9067141 (32)\ttotal: 7.01s\tremaining: 3m 7s\n",
      "36:\tlearn: 39160.3689373\ttest: 18075.5980968\tbest: 17615.9067141 (32)\ttotal: 7.22s\tremaining: 3m 7s\n",
      "37:\tlearn: 39156.5048912\ttest: 18087.9344066\tbest: 17615.9067141 (32)\ttotal: 7.35s\tremaining: 3m 5s\n",
      "38:\tlearn: 39016.4619003\ttest: 18088.4293861\tbest: 17615.9067141 (32)\ttotal: 7.54s\tremaining: 3m 5s\n",
      "39:\tlearn: 38891.1622319\ttest: 18061.5099574\tbest: 17615.9067141 (32)\ttotal: 7.74s\tremaining: 3m 5s\n",
      "40:\tlearn: 38869.0592395\ttest: 18060.6209745\tbest: 17615.9067141 (32)\ttotal: 7.93s\tremaining: 3m 5s\n",
      "41:\tlearn: 38864.1042987\ttest: 18051.9409580\tbest: 17615.9067141 (32)\ttotal: 8.15s\tremaining: 3m 5s\n",
      "42:\tlearn: 38833.5984844\ttest: 18055.0780051\tbest: 17615.9067141 (32)\ttotal: 8.35s\tremaining: 3m 5s\n",
      "43:\tlearn: 38809.4572988\ttest: 18023.1289018\tbest: 17615.9067141 (32)\ttotal: 8.54s\tremaining: 3m 5s\n",
      "44:\tlearn: 38781.9010695\ttest: 18032.2598793\tbest: 17615.9067141 (32)\ttotal: 8.75s\tremaining: 3m 5s\n",
      "45:\tlearn: 38769.4256369\ttest: 18016.7233555\tbest: 17615.9067141 (32)\ttotal: 8.99s\tremaining: 3m 6s\n",
      "46:\tlearn: 38612.8622800\ttest: 18075.3238030\tbest: 17615.9067141 (32)\ttotal: 9.15s\tremaining: 3m 5s\n",
      "47:\tlearn: 38265.0874552\ttest: 18512.3216240\tbest: 17615.9067141 (32)\ttotal: 9.34s\tremaining: 3m 5s\n",
      "48:\tlearn: 38264.2925337\ttest: 18515.0333726\tbest: 17615.9067141 (32)\ttotal: 9.47s\tremaining: 3m 3s\n",
      "49:\tlearn: 38210.2754182\ttest: 18613.7354837\tbest: 17615.9067141 (32)\ttotal: 9.65s\tremaining: 3m 3s\n",
      "50:\tlearn: 38183.8669673\ttest: 18593.3264367\tbest: 17615.9067141 (32)\ttotal: 9.86s\tremaining: 3m 3s\n",
      "51:\tlearn: 37881.3046609\ttest: 18700.0472942\tbest: 17615.9067141 (32)\ttotal: 10.1s\tremaining: 3m 3s\n",
      "52:\tlearn: 37727.0971263\ttest: 18718.1980624\tbest: 17615.9067141 (32)\ttotal: 10.3s\tremaining: 3m 3s\n",
      "53:\tlearn: 37703.8212667\ttest: 18699.2342903\tbest: 17615.9067141 (32)\ttotal: 10.4s\tremaining: 3m 3s\n",
      "54:\tlearn: 37498.1577953\ttest: 18767.9840942\tbest: 17615.9067141 (32)\ttotal: 10.7s\tremaining: 3m 3s\n",
      "55:\tlearn: 37244.0120451\ttest: 19260.3316934\tbest: 17615.9067141 (32)\ttotal: 10.9s\tremaining: 3m 3s\n",
      "56:\tlearn: 37174.6563869\ttest: 19277.1187090\tbest: 17615.9067141 (32)\ttotal: 11.1s\tremaining: 3m 2s\n",
      "57:\tlearn: 36935.2525184\ttest: 19422.7453721\tbest: 17615.9067141 (32)\ttotal: 11.3s\tremaining: 3m 2s\n",
      "58:\tlearn: 36914.5466229\ttest: 19385.6114166\tbest: 17615.9067141 (32)\ttotal: 11.5s\tremaining: 3m 3s\n",
      "59:\tlearn: 36864.8319113\ttest: 19722.1110137\tbest: 17615.9067141 (32)\ttotal: 11.7s\tremaining: 3m 2s\n",
      "60:\tlearn: 36720.2735659\ttest: 19679.3948256\tbest: 17615.9067141 (32)\ttotal: 11.9s\tremaining: 3m 2s\n",
      "61:\tlearn: 36682.4177904\ttest: 19677.7091337\tbest: 17615.9067141 (32)\ttotal: 12.1s\tremaining: 3m 2s\n",
      "62:\tlearn: 36644.7098412\ttest: 19663.7809241\tbest: 17615.9067141 (32)\ttotal: 12.3s\tremaining: 3m 2s\n",
      "63:\tlearn: 36589.3360312\ttest: 19646.9421295\tbest: 17615.9067141 (32)\ttotal: 12.5s\tremaining: 3m 2s\n",
      "64:\tlearn: 36428.2486570\ttest: 19660.6394889\tbest: 17615.9067141 (32)\ttotal: 12.7s\tremaining: 3m 2s\n",
      "65:\tlearn: 36332.6916005\ttest: 19647.4769347\tbest: 17615.9067141 (32)\ttotal: 12.9s\tremaining: 3m 2s\n",
      "66:\tlearn: 36171.2617720\ttest: 20044.6726063\tbest: 17615.9067141 (32)\ttotal: 13.1s\tremaining: 3m 1s\n",
      "67:\tlearn: 36054.6396710\ttest: 20237.0211975\tbest: 17615.9067141 (32)\ttotal: 13.3s\tremaining: 3m 1s\n",
      "68:\tlearn: 35898.9816006\ttest: 20241.2893297\tbest: 17615.9067141 (32)\ttotal: 13.5s\tremaining: 3m 1s\n",
      "69:\tlearn: 35875.4458767\ttest: 20236.6673492\tbest: 17615.9067141 (32)\ttotal: 13.7s\tremaining: 3m 1s\n",
      "70:\tlearn: 35846.8431140\ttest: 20232.3922519\tbest: 17615.9067141 (32)\ttotal: 13.9s\tremaining: 3m 1s\n",
      "71:\tlearn: 35647.2203142\ttest: 20086.8425355\tbest: 17615.9067141 (32)\ttotal: 14.1s\tremaining: 3m 1s\n",
      "72:\tlearn: 35622.9764361\ttest: 20046.3730684\tbest: 17615.9067141 (32)\ttotal: 14.3s\tremaining: 3m 1s\n",
      "73:\tlearn: 35620.4820569\ttest: 20033.0475605\tbest: 17615.9067141 (32)\ttotal: 14.5s\tremaining: 3m 1s\n",
      "74:\tlearn: 35602.5556573\ttest: 20009.3381266\tbest: 17615.9067141 (32)\ttotal: 14.7s\tremaining: 3m 1s\n",
      "75:\tlearn: 35576.7011427\ttest: 19977.0650053\tbest: 17615.9067141 (32)\ttotal: 14.9s\tremaining: 3m 1s\n",
      "76:\tlearn: 35576.7011426\ttest: 19977.0604555\tbest: 17615.9067141 (32)\ttotal: 15s\tremaining: 2m 59s\n",
      "77:\tlearn: 35574.1163150\ttest: 19965.1899124\tbest: 17615.9067141 (32)\ttotal: 15.1s\tremaining: 2m 59s\n",
      "78:\tlearn: 35557.9159495\ttest: 19959.4660591\tbest: 17615.9067141 (32)\ttotal: 15.3s\tremaining: 2m 58s\n",
      "79:\tlearn: 35492.6399432\ttest: 19975.6407472\tbest: 17615.9067141 (32)\ttotal: 15.5s\tremaining: 2m 58s\n",
      "80:\tlearn: 35485.0790824\ttest: 19959.7296304\tbest: 17615.9067141 (32)\ttotal: 15.7s\tremaining: 2m 58s\n",
      "81:\tlearn: 35472.8663162\ttest: 19948.4788902\tbest: 17615.9067141 (32)\ttotal: 15.9s\tremaining: 2m 58s\n",
      "82:\tlearn: 35456.7978402\ttest: 19944.2246990\tbest: 17615.9067141 (32)\ttotal: 16.1s\tremaining: 2m 58s\n",
      "83:\tlearn: 35446.5284709\ttest: 19937.0222343\tbest: 17615.9067141 (32)\ttotal: 16.3s\tremaining: 2m 57s\n",
      "84:\tlearn: 35398.8345354\ttest: 19910.3177695\tbest: 17615.9067141 (32)\ttotal: 16.5s\tremaining: 2m 57s\n",
      "85:\tlearn: 35308.1433975\ttest: 19880.7280334\tbest: 17615.9067141 (32)\ttotal: 16.7s\tremaining: 2m 57s\n",
      "86:\tlearn: 35299.3593960\ttest: 19860.3940956\tbest: 17615.9067141 (32)\ttotal: 16.9s\tremaining: 2m 57s\n",
      "87:\tlearn: 35298.6329668\ttest: 19860.0508565\tbest: 17615.9067141 (32)\ttotal: 17s\tremaining: 2m 56s\n",
      "88:\tlearn: 35297.0623479\ttest: 19864.8589750\tbest: 17615.9067141 (32)\ttotal: 17.1s\tremaining: 2m 55s\n",
      "89:\tlearn: 35288.2761748\ttest: 19850.3610834\tbest: 17615.9067141 (32)\ttotal: 17.3s\tremaining: 2m 55s\n",
      "90:\tlearn: 35279.8117694\ttest: 19857.4142313\tbest: 17615.9067141 (32)\ttotal: 17.5s\tremaining: 2m 55s\n",
      "91:\tlearn: 35273.1370152\ttest: 19855.8764584\tbest: 17615.9067141 (32)\ttotal: 17.8s\tremaining: 2m 55s\n",
      "92:\tlearn: 35119.2086123\ttest: 19876.9032716\tbest: 17615.9067141 (32)\ttotal: 17.9s\tremaining: 2m 55s\n",
      "93:\tlearn: 35056.6075550\ttest: 19863.4739849\tbest: 17615.9067141 (32)\ttotal: 18.1s\tremaining: 2m 54s\n",
      "94:\tlearn: 35052.7079675\ttest: 19876.7458613\tbest: 17615.9067141 (32)\ttotal: 18.3s\tremaining: 2m 54s\n",
      "95:\tlearn: 35025.0648973\ttest: 19875.5435103\tbest: 17615.9067141 (32)\ttotal: 18.6s\tremaining: 2m 54s\n",
      "96:\tlearn: 34997.4373518\ttest: 19861.0593724\tbest: 17615.9067141 (32)\ttotal: 18.7s\tremaining: 2m 54s\n",
      "97:\tlearn: 34990.3158029\ttest: 19844.8119284\tbest: 17615.9067141 (32)\ttotal: 19s\tremaining: 2m 54s\n",
      "98:\tlearn: 34926.1701738\ttest: 19788.9709137\tbest: 17615.9067141 (32)\ttotal: 19.2s\tremaining: 2m 54s\n",
      "99:\tlearn: 34919.1235149\ttest: 19791.1249973\tbest: 17615.9067141 (32)\ttotal: 19.4s\tremaining: 2m 54s\n",
      "100:\tlearn: 34510.9493226\ttest: 20483.9203816\tbest: 17615.9067141 (32)\ttotal: 19.6s\tremaining: 2m 54s\n",
      "101:\tlearn: 34504.1126239\ttest: 20469.0073767\tbest: 17615.9067141 (32)\ttotal: 19.8s\tremaining: 2m 54s\n",
      "102:\tlearn: 34503.5135007\ttest: 20471.5711661\tbest: 17615.9067141 (32)\ttotal: 19.9s\tremaining: 2m 53s\n",
      "103:\tlearn: 34351.5553884\ttest: 20850.2171120\tbest: 17615.9067141 (32)\ttotal: 20.1s\tremaining: 2m 53s\n",
      "104:\tlearn: 34330.0568416\ttest: 20856.9424857\tbest: 17615.9067141 (32)\ttotal: 20.3s\tremaining: 2m 52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105:\tlearn: 34320.3394310\ttest: 20857.3721154\tbest: 17615.9067141 (32)\ttotal: 20.5s\tremaining: 2m 52s\n",
      "106:\tlearn: 34248.7910242\ttest: 20824.5939908\tbest: 17615.9067141 (32)\ttotal: 20.7s\tremaining: 2m 52s\n",
      "107:\tlearn: 34241.0057878\ttest: 20826.7517553\tbest: 17615.9067141 (32)\ttotal: 20.9s\tremaining: 2m 52s\n",
      "108:\tlearn: 34212.0935515\ttest: 20806.2653289\tbest: 17615.9067141 (32)\ttotal: 21.1s\tremaining: 2m 52s\n",
      "109:\tlearn: 33993.1870945\ttest: 21218.6772123\tbest: 17615.9067141 (32)\ttotal: 21.3s\tremaining: 2m 52s\n",
      "110:\tlearn: 33950.6156851\ttest: 21199.2564840\tbest: 17615.9067141 (32)\ttotal: 21.5s\tremaining: 2m 52s\n",
      "111:\tlearn: 33876.9547890\ttest: 21182.9768762\tbest: 17615.9067141 (32)\ttotal: 21.7s\tremaining: 2m 52s\n",
      "112:\tlearn: 33799.2033945\ttest: 21169.9330182\tbest: 17615.9067141 (32)\ttotal: 21.9s\tremaining: 2m 51s\n",
      "113:\tlearn: 33774.2696872\ttest: 21033.1952331\tbest: 17615.9067141 (32)\ttotal: 22.1s\tremaining: 2m 51s\n",
      "114:\tlearn: 33762.4083195\ttest: 21038.3663467\tbest: 17615.9067141 (32)\ttotal: 22.3s\tremaining: 2m 51s\n",
      "115:\tlearn: 33708.2304295\ttest: 21164.2518410\tbest: 17615.9067141 (32)\ttotal: 22.5s\tremaining: 2m 51s\n",
      "116:\tlearn: 33621.5434214\ttest: 21327.1412948\tbest: 17615.9067141 (32)\ttotal: 22.7s\tremaining: 2m 51s\n",
      "117:\tlearn: 33612.7384025\ttest: 21322.1372522\tbest: 17615.9067141 (32)\ttotal: 22.9s\tremaining: 2m 51s\n",
      "118:\tlearn: 33610.4182767\ttest: 21319.6794649\tbest: 17615.9067141 (32)\ttotal: 23.1s\tremaining: 2m 50s\n",
      "119:\tlearn: 33596.3705128\ttest: 21348.4383690\tbest: 17615.9067141 (32)\ttotal: 23.3s\tremaining: 2m 50s\n",
      "120:\tlearn: 33570.7624547\ttest: 21344.7154652\tbest: 17615.9067141 (32)\ttotal: 23.4s\tremaining: 2m 50s\n",
      "121:\tlearn: 33519.2558686\ttest: 21344.8663956\tbest: 17615.9067141 (32)\ttotal: 23.6s\tremaining: 2m 50s\n",
      "122:\tlearn: 33481.3622772\ttest: 21364.4244768\tbest: 17615.9067141 (32)\ttotal: 23.8s\tremaining: 2m 50s\n",
      "123:\tlearn: 33471.1669300\ttest: 21359.9923174\tbest: 17615.9067141 (32)\ttotal: 24.1s\tremaining: 2m 49s\n",
      "124:\tlearn: 33471.1633501\ttest: 21359.9959834\tbest: 17615.9067141 (32)\ttotal: 24.2s\tremaining: 2m 49s\n",
      "125:\tlearn: 33457.8038372\ttest: 21339.1059377\tbest: 17615.9067141 (32)\ttotal: 24.4s\tremaining: 2m 49s\n",
      "126:\tlearn: 33389.6516195\ttest: 21262.9773944\tbest: 17615.9067141 (32)\ttotal: 24.6s\tremaining: 2m 49s\n",
      "127:\tlearn: 33365.5640293\ttest: 21243.3155894\tbest: 17615.9067141 (32)\ttotal: 24.8s\tremaining: 2m 48s\n",
      "128:\tlearn: 33363.4972273\ttest: 21243.1151716\tbest: 17615.9067141 (32)\ttotal: 25s\tremaining: 2m 48s\n",
      "129:\tlearn: 33362.9583420\ttest: 21246.1175329\tbest: 17615.9067141 (32)\ttotal: 25.2s\tremaining: 2m 48s\n",
      "130:\tlearn: 33318.0369192\ttest: 21379.5368719\tbest: 17615.9067141 (32)\ttotal: 25.4s\tremaining: 2m 48s\n",
      "131:\tlearn: 33315.6105848\ttest: 21376.9690978\tbest: 17615.9067141 (32)\ttotal: 25.6s\tremaining: 2m 48s\n",
      "132:\tlearn: 33309.4062540\ttest: 21383.1321952\tbest: 17615.9067141 (32)\ttotal: 25.8s\tremaining: 2m 48s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 17615.90671\n",
      "bestIteration = 32\n",
      "\n",
      "Shrink model to first 33 iterations.\n",
      "Learning rate set to 0.198741\n",
      "0:\tlearn: 56261.9620144\ttest: 28820.0083217\tbest: 28820.0083217 (0)\ttotal: 184ms\tremaining: 3m 3s\n",
      "1:\tlearn: 53464.6848421\ttest: 25530.5925258\tbest: 25530.5925258 (1)\ttotal: 383ms\tremaining: 3m 11s\n",
      "2:\tlearn: 50937.7911691\ttest: 23259.1950127\tbest: 23259.1950127 (2)\ttotal: 572ms\tremaining: 3m 10s\n",
      "3:\tlearn: 49529.1075320\ttest: 21223.3211007\tbest: 21223.3211007 (3)\ttotal: 768ms\tremaining: 3m 11s\n",
      "4:\tlearn: 48229.2803918\ttest: 20167.8094188\tbest: 20167.8094188 (4)\ttotal: 997ms\tremaining: 3m 18s\n",
      "5:\tlearn: 47104.2503127\ttest: 18729.5974951\tbest: 18729.5974951 (5)\ttotal: 1.2s\tremaining: 3m 19s\n",
      "6:\tlearn: 45704.6455998\ttest: 18723.6451630\tbest: 18723.6451630 (6)\ttotal: 1.41s\tremaining: 3m 19s\n",
      "7:\tlearn: 45263.9281256\ttest: 18048.9361370\tbest: 18048.9361370 (7)\ttotal: 1.61s\tremaining: 3m 19s\n",
      "8:\tlearn: 44276.3303765\ttest: 17372.8519711\tbest: 17372.8519711 (8)\ttotal: 1.82s\tremaining: 3m 20s\n",
      "9:\tlearn: 43793.4733047\ttest: 16912.0222366\tbest: 16912.0222366 (9)\ttotal: 2.03s\tremaining: 3m 21s\n",
      "10:\tlearn: 43448.2143260\ttest: 16957.4262274\tbest: 16912.0222366 (9)\ttotal: 2.23s\tremaining: 3m 20s\n",
      "11:\tlearn: 42935.9279786\ttest: 16914.8884791\tbest: 16912.0222366 (9)\ttotal: 2.43s\tremaining: 3m 20s\n",
      "12:\tlearn: 42849.6124698\ttest: 16919.7923516\tbest: 16912.0222366 (9)\ttotal: 2.63s\tremaining: 3m 19s\n",
      "13:\tlearn: 42702.6964665\ttest: 16564.3792419\tbest: 16564.3792419 (13)\ttotal: 2.86s\tremaining: 3m 21s\n",
      "14:\tlearn: 42408.5153956\ttest: 16578.5999815\tbest: 16564.3792419 (13)\ttotal: 3.05s\tremaining: 3m 20s\n",
      "15:\tlearn: 42305.1322873\ttest: 16590.7782006\tbest: 16564.3792419 (13)\ttotal: 3.27s\tremaining: 3m 20s\n",
      "16:\tlearn: 42268.9145756\ttest: 16490.9006013\tbest: 16490.9006013 (16)\ttotal: 3.41s\tremaining: 3m 17s\n",
      "17:\tlearn: 42048.2401474\ttest: 16540.6268940\tbest: 16490.9006013 (16)\ttotal: 3.6s\tremaining: 3m 16s\n",
      "18:\tlearn: 41898.0675974\ttest: 16353.6434638\tbest: 16353.6434638 (18)\ttotal: 3.83s\tremaining: 3m 17s\n",
      "19:\tlearn: 41423.3852556\ttest: 16271.5197724\tbest: 16271.5197724 (19)\ttotal: 4.03s\tremaining: 3m 17s\n",
      "20:\tlearn: 41343.3618016\ttest: 16163.5082270\tbest: 16163.5082270 (20)\ttotal: 4.23s\tremaining: 3m 17s\n",
      "21:\tlearn: 41213.9123000\ttest: 16139.3916730\tbest: 16139.3916730 (21)\ttotal: 4.42s\tremaining: 3m 16s\n",
      "22:\tlearn: 41168.9788362\ttest: 16103.2865510\tbest: 16103.2865510 (22)\ttotal: 4.65s\tremaining: 3m 17s\n",
      "23:\tlearn: 41038.7782137\ttest: 16063.4507587\tbest: 16063.4507587 (23)\ttotal: 4.87s\tremaining: 3m 17s\n",
      "24:\tlearn: 40943.4405168\ttest: 15919.7984992\tbest: 15919.7984992 (24)\ttotal: 5.09s\tremaining: 3m 18s\n",
      "25:\tlearn: 40922.5054511\ttest: 15886.7829818\tbest: 15886.7829818 (25)\ttotal: 5.22s\tremaining: 3m 15s\n",
      "26:\tlearn: 40155.6069405\ttest: 16281.6998604\tbest: 15886.7829818 (25)\ttotal: 5.42s\tremaining: 3m 15s\n",
      "27:\tlearn: 40058.8504964\ttest: 16273.7728377\tbest: 15886.7829818 (25)\ttotal: 5.62s\tremaining: 3m 15s\n",
      "28:\tlearn: 40058.8504716\ttest: 16273.7449478\tbest: 15886.7829818 (25)\ttotal: 5.72s\tremaining: 3m 11s\n",
      "29:\tlearn: 39998.0133518\ttest: 16188.5061119\tbest: 15886.7829818 (25)\ttotal: 5.93s\tremaining: 3m 11s\n",
      "30:\tlearn: 39941.7889236\ttest: 16152.4322547\tbest: 15886.7829818 (25)\ttotal: 6.13s\tremaining: 3m 11s\n",
      "31:\tlearn: 39895.9395630\ttest: 16079.1754558\tbest: 15886.7829818 (25)\ttotal: 6.36s\tremaining: 3m 12s\n",
      "32:\tlearn: 39847.0059184\ttest: 15992.5478842\tbest: 15886.7829818 (25)\ttotal: 6.57s\tremaining: 3m 12s\n",
      "33:\tlearn: 39686.6157290\ttest: 16070.0080056\tbest: 15886.7829818 (25)\ttotal: 6.78s\tremaining: 3m 12s\n",
      "34:\tlearn: 39485.3352876\ttest: 16221.0730381\tbest: 15886.7829818 (25)\ttotal: 6.99s\tremaining: 3m 12s\n",
      "35:\tlearn: 39462.6807055\ttest: 16202.3633118\tbest: 15886.7829818 (25)\ttotal: 7.21s\tremaining: 3m 13s\n",
      "36:\tlearn: 39462.5990800\ttest: 16202.8989951\tbest: 15886.7829818 (25)\ttotal: 7.33s\tremaining: 3m 10s\n",
      "37:\tlearn: 39450.3874245\ttest: 16194.7554008\tbest: 15886.7829818 (25)\ttotal: 7.47s\tremaining: 3m 9s\n",
      "38:\tlearn: 38831.2725665\ttest: 16208.3309629\tbest: 15886.7829818 (25)\ttotal: 7.71s\tremaining: 3m 10s\n",
      "39:\tlearn: 38812.6875663\ttest: 16184.5928942\tbest: 15886.7829818 (25)\ttotal: 7.93s\tremaining: 3m 10s\n",
      "40:\tlearn: 38684.6975627\ttest: 16324.6179803\tbest: 15886.7829818 (25)\ttotal: 8.14s\tremaining: 3m 10s\n",
      "41:\tlearn: 38652.6613793\ttest: 16319.8449198\tbest: 15886.7829818 (25)\ttotal: 8.34s\tremaining: 3m 10s\n",
      "42:\tlearn: 38614.3528980\ttest: 16273.7738241\tbest: 15886.7829818 (25)\ttotal: 8.54s\tremaining: 3m 10s\n",
      "43:\tlearn: 38319.1248117\ttest: 16202.6051186\tbest: 15886.7829818 (25)\ttotal: 8.74s\tremaining: 3m 9s\n",
      "44:\tlearn: 38319.1248020\ttest: 16202.5783301\tbest: 15886.7829818 (25)\ttotal: 8.84s\tremaining: 3m 7s\n",
      "45:\tlearn: 37960.1580238\ttest: 16155.3617448\tbest: 15886.7829818 (25)\ttotal: 9.06s\tremaining: 3m 7s\n",
      "46:\tlearn: 37840.4216584\ttest: 16128.1598367\tbest: 15886.7829818 (25)\ttotal: 9.24s\tremaining: 3m 7s\n",
      "47:\tlearn: 37752.0770661\ttest: 16130.8536135\tbest: 15886.7829818 (25)\ttotal: 9.42s\tremaining: 3m 6s\n",
      "48:\tlearn: 37516.0039987\ttest: 16136.3848862\tbest: 15886.7829818 (25)\ttotal: 9.62s\tremaining: 3m 6s\n",
      "49:\tlearn: 37488.1717892\ttest: 16135.8890382\tbest: 15886.7829818 (25)\ttotal: 9.84s\tremaining: 3m 6s\n",
      "50:\tlearn: 37486.1636848\ttest: 16139.0059518\tbest: 15886.7829818 (25)\ttotal: 9.97s\tremaining: 3m 5s\n",
      "51:\tlearn: 37410.3712933\ttest: 16373.3341738\tbest: 15886.7829818 (25)\ttotal: 10.2s\tremaining: 3m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52:\tlearn: 37240.1624050\ttest: 16589.1280121\tbest: 15886.7829818 (25)\ttotal: 10.4s\tremaining: 3m 6s\n",
      "53:\tlearn: 37235.9178460\ttest: 16595.9068933\tbest: 15886.7829818 (25)\ttotal: 10.6s\tremaining: 3m 5s\n",
      "54:\tlearn: 37138.0120515\ttest: 16669.0016820\tbest: 15886.7829818 (25)\ttotal: 10.8s\tremaining: 3m 4s\n",
      "55:\tlearn: 37114.9638355\ttest: 16639.2361329\tbest: 15886.7829818 (25)\ttotal: 11s\tremaining: 3m 4s\n",
      "56:\tlearn: 37088.7583123\ttest: 16651.8809295\tbest: 15886.7829818 (25)\ttotal: 11.2s\tremaining: 3m 4s\n",
      "57:\tlearn: 37068.6206589\ttest: 16654.3373102\tbest: 15886.7829818 (25)\ttotal: 11.4s\tremaining: 3m 5s\n",
      "58:\tlearn: 37045.4982231\ttest: 16663.8946840\tbest: 15886.7829818 (25)\ttotal: 11.6s\tremaining: 3m 5s\n",
      "59:\tlearn: 37032.7660218\ttest: 16628.4773120\tbest: 15886.7829818 (25)\ttotal: 11.8s\tremaining: 3m 4s\n",
      "60:\tlearn: 37022.1067526\ttest: 16638.1750492\tbest: 15886.7829818 (25)\ttotal: 12s\tremaining: 3m 5s\n",
      "61:\tlearn: 37004.3056008\ttest: 16631.1763167\tbest: 15886.7829818 (25)\ttotal: 12.2s\tremaining: 3m 5s\n",
      "62:\tlearn: 36966.4247025\ttest: 16602.6740068\tbest: 15886.7829818 (25)\ttotal: 12.4s\tremaining: 3m 4s\n",
      "63:\tlearn: 36947.7904442\ttest: 16586.4042656\tbest: 15886.7829818 (25)\ttotal: 12.6s\tremaining: 3m 4s\n",
      "64:\tlearn: 36817.5471330\ttest: 16626.5931986\tbest: 15886.7829818 (25)\ttotal: 12.9s\tremaining: 3m 5s\n",
      "65:\tlearn: 36816.8698715\ttest: 16621.2840140\tbest: 15886.7829818 (25)\ttotal: 13s\tremaining: 3m 3s\n",
      "66:\tlearn: 36699.7338077\ttest: 16597.4045325\tbest: 15886.7829818 (25)\ttotal: 13.2s\tremaining: 3m 3s\n",
      "67:\tlearn: 36666.0219413\ttest: 16606.1882737\tbest: 15886.7829818 (25)\ttotal: 13.4s\tremaining: 3m 3s\n",
      "68:\tlearn: 36656.2424292\ttest: 16577.1721946\tbest: 15886.7829818 (25)\ttotal: 13.6s\tremaining: 3m 3s\n",
      "69:\tlearn: 36435.3133259\ttest: 16592.3427240\tbest: 15886.7829818 (25)\ttotal: 13.8s\tremaining: 3m 3s\n",
      "70:\tlearn: 36431.2328700\ttest: 16587.3785599\tbest: 15886.7829818 (25)\ttotal: 14s\tremaining: 3m 3s\n",
      "71:\tlearn: 36407.0587008\ttest: 16614.0389903\tbest: 15886.7829818 (25)\ttotal: 14.2s\tremaining: 3m 3s\n",
      "72:\tlearn: 36405.0187885\ttest: 16605.4267185\tbest: 15886.7829818 (25)\ttotal: 14.5s\tremaining: 3m 3s\n",
      "73:\tlearn: 36325.0761901\ttest: 16624.7546834\tbest: 15886.7829818 (25)\ttotal: 14.6s\tremaining: 3m 3s\n",
      "74:\tlearn: 36233.8100332\ttest: 16623.6020631\tbest: 15886.7829818 (25)\ttotal: 14.9s\tremaining: 3m 3s\n",
      "75:\tlearn: 36230.0192529\ttest: 16618.4541747\tbest: 15886.7829818 (25)\ttotal: 15.1s\tremaining: 3m 3s\n",
      "76:\tlearn: 36110.0911110\ttest: 16564.2882589\tbest: 15886.7829818 (25)\ttotal: 15.3s\tremaining: 3m 3s\n",
      "77:\tlearn: 36095.7949378\ttest: 16566.5359628\tbest: 15886.7829818 (25)\ttotal: 15.5s\tremaining: 3m 3s\n",
      "78:\tlearn: 36010.2254183\ttest: 16440.9632793\tbest: 15886.7829818 (25)\ttotal: 15.7s\tremaining: 3m 3s\n",
      "79:\tlearn: 35970.5712633\ttest: 16400.2133236\tbest: 15886.7829818 (25)\ttotal: 15.9s\tremaining: 3m 3s\n",
      "80:\tlearn: 35925.1310908\ttest: 16368.4555383\tbest: 15886.7829818 (25)\ttotal: 16.1s\tremaining: 3m 3s\n",
      "81:\tlearn: 35905.4333446\ttest: 16327.8345586\tbest: 15886.7829818 (25)\ttotal: 16.3s\tremaining: 3m 2s\n",
      "82:\tlearn: 35783.8860571\ttest: 16381.5295016\tbest: 15886.7829818 (25)\ttotal: 16.5s\tremaining: 3m 2s\n",
      "83:\tlearn: 35771.5463629\ttest: 16354.2367207\tbest: 15886.7829818 (25)\ttotal: 16.7s\tremaining: 3m 2s\n",
      "84:\tlearn: 35755.6687361\ttest: 16353.4069789\tbest: 15886.7829818 (25)\ttotal: 16.9s\tremaining: 3m 2s\n",
      "85:\tlearn: 35714.6297302\ttest: 16360.8818348\tbest: 15886.7829818 (25)\ttotal: 17.1s\tremaining: 3m 2s\n",
      "86:\tlearn: 35704.2439312\ttest: 16366.4593447\tbest: 15886.7829818 (25)\ttotal: 17.3s\tremaining: 3m 1s\n",
      "87:\tlearn: 35700.6512776\ttest: 16352.9495125\tbest: 15886.7829818 (25)\ttotal: 17.6s\tremaining: 3m 2s\n",
      "88:\tlearn: 35698.8168696\ttest: 16358.9755309\tbest: 15886.7829818 (25)\ttotal: 17.8s\tremaining: 3m 1s\n",
      "89:\tlearn: 35698.2995966\ttest: 16352.4320210\tbest: 15886.7829818 (25)\ttotal: 17.9s\tremaining: 3m\n",
      "90:\tlearn: 35680.2034340\ttest: 16337.1412715\tbest: 15886.7829818 (25)\ttotal: 18.1s\tremaining: 3m\n",
      "91:\tlearn: 35466.6444566\ttest: 16567.4613915\tbest: 15886.7829818 (25)\ttotal: 18.3s\tremaining: 3m\n",
      "92:\tlearn: 35456.0631106\ttest: 16529.3050831\tbest: 15886.7829818 (25)\ttotal: 18.5s\tremaining: 3m\n",
      "93:\tlearn: 35448.8225930\ttest: 16525.6403471\tbest: 15886.7829818 (25)\ttotal: 18.8s\tremaining: 3m\n",
      "94:\tlearn: 35275.2412446\ttest: 16561.7804562\tbest: 15886.7829818 (25)\ttotal: 19s\tremaining: 3m\n",
      "95:\tlearn: 35264.1236393\ttest: 16560.7908119\tbest: 15886.7829818 (25)\ttotal: 19.2s\tremaining: 3m\n",
      "96:\tlearn: 35264.1236393\ttest: 16560.7891120\tbest: 15886.7829818 (25)\ttotal: 19.3s\tremaining: 2m 59s\n",
      "97:\tlearn: 35226.4729184\ttest: 16637.2439752\tbest: 15886.7829818 (25)\ttotal: 19.5s\tremaining: 2m 59s\n",
      "98:\tlearn: 35202.5711308\ttest: 16649.5990729\tbest: 15886.7829818 (25)\ttotal: 19.7s\tremaining: 2m 59s\n",
      "99:\tlearn: 35191.5526902\ttest: 16647.0921595\tbest: 15886.7829818 (25)\ttotal: 19.9s\tremaining: 2m 59s\n",
      "100:\tlearn: 35191.5302359\ttest: 16647.8156942\tbest: 15886.7829818 (25)\ttotal: 20s\tremaining: 2m 58s\n",
      "101:\tlearn: 35181.7669638\ttest: 16643.2076017\tbest: 15886.7829818 (25)\ttotal: 20.3s\tremaining: 2m 58s\n",
      "102:\tlearn: 35181.7669638\ttest: 16643.2067015\tbest: 15886.7829818 (25)\ttotal: 20.4s\tremaining: 2m 57s\n",
      "103:\tlearn: 35169.5502119\ttest: 16628.2748248\tbest: 15886.7829818 (25)\ttotal: 20.6s\tremaining: 2m 57s\n",
      "104:\tlearn: 35070.1960537\ttest: 16614.8092080\tbest: 15886.7829818 (25)\ttotal: 20.8s\tremaining: 2m 56s\n",
      "105:\tlearn: 35057.4086117\ttest: 16617.5434059\tbest: 15886.7829818 (25)\ttotal: 21s\tremaining: 2m 56s\n",
      "106:\tlearn: 35050.1807630\ttest: 16603.6151949\tbest: 15886.7829818 (25)\ttotal: 21.2s\tremaining: 2m 56s\n",
      "107:\tlearn: 35042.5578302\ttest: 16598.7572521\tbest: 15886.7829818 (25)\ttotal: 21.4s\tremaining: 2m 56s\n",
      "108:\tlearn: 34972.8026336\ttest: 16661.2086618\tbest: 15886.7829818 (25)\ttotal: 21.5s\tremaining: 2m 56s\n",
      "109:\tlearn: 34967.9490900\ttest: 16653.8266557\tbest: 15886.7829818 (25)\ttotal: 21.8s\tremaining: 2m 56s\n",
      "110:\tlearn: 34967.9053899\ttest: 16654.4169143\tbest: 15886.7829818 (25)\ttotal: 21.9s\tremaining: 2m 55s\n",
      "111:\tlearn: 34960.9463181\ttest: 16642.9081878\tbest: 15886.7829818 (25)\ttotal: 22.1s\tremaining: 2m 55s\n",
      "112:\tlearn: 34936.1834831\ttest: 16714.0067707\tbest: 15886.7829818 (25)\ttotal: 22.3s\tremaining: 2m 55s\n",
      "113:\tlearn: 34908.1117149\ttest: 16702.2031840\tbest: 15886.7829818 (25)\ttotal: 22.5s\tremaining: 2m 54s\n",
      "114:\tlearn: 34855.5971096\ttest: 16686.8516281\tbest: 15886.7829818 (25)\ttotal: 22.7s\tremaining: 2m 54s\n",
      "115:\tlearn: 34855.4660641\ttest: 16686.1353021\tbest: 15886.7829818 (25)\ttotal: 22.8s\tremaining: 2m 53s\n",
      "116:\tlearn: 34825.8024814\ttest: 16698.9419653\tbest: 15886.7829818 (25)\ttotal: 23s\tremaining: 2m 53s\n",
      "117:\tlearn: 34817.5639213\ttest: 16715.4342477\tbest: 15886.7829818 (25)\ttotal: 23.2s\tremaining: 2m 53s\n",
      "118:\tlearn: 34794.4288477\ttest: 16713.7256536\tbest: 15886.7829818 (25)\ttotal: 23.5s\tremaining: 2m 53s\n",
      "119:\tlearn: 34790.7535484\ttest: 16712.9995859\tbest: 15886.7829818 (25)\ttotal: 23.7s\tremaining: 2m 53s\n",
      "120:\tlearn: 34730.1247607\ttest: 16858.6731794\tbest: 15886.7829818 (25)\ttotal: 23.9s\tremaining: 2m 53s\n",
      "121:\tlearn: 34725.5777446\ttest: 16853.6779537\tbest: 15886.7829818 (25)\ttotal: 24.1s\tremaining: 2m 53s\n",
      "122:\tlearn: 34710.7831952\ttest: 16804.0462827\tbest: 15886.7829818 (25)\ttotal: 24.3s\tremaining: 2m 53s\n",
      "123:\tlearn: 34631.6375621\ttest: 16818.7909178\tbest: 15886.7829818 (25)\ttotal: 24.5s\tremaining: 2m 52s\n",
      "124:\tlearn: 34617.3564669\ttest: 16822.3483554\tbest: 15886.7829818 (25)\ttotal: 24.7s\tremaining: 2m 52s\n",
      "125:\tlearn: 34616.1993624\ttest: 16815.3995954\tbest: 15886.7829818 (25)\ttotal: 24.8s\tremaining: 2m 52s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 15886.78298\n",
      "bestIteration = 25\n",
      "\n",
      "Shrink model to first 26 iterations.\n",
      "Learning rate set to 0.201566\n",
      "0:\tlearn: 54382.2608109\ttest: 29770.7178665\tbest: 29770.7178665 (0)\ttotal: 222ms\tremaining: 3m 42s\n",
      "1:\tlearn: 52893.9889810\ttest: 27540.9860918\tbest: 27540.9860918 (1)\ttotal: 428ms\tremaining: 3m 33s\n",
      "2:\tlearn: 52733.8930586\ttest: 27174.7513305\tbest: 27174.7513305 (2)\ttotal: 545ms\tremaining: 3m 1s\n",
      "3:\tlearn: 51140.7639390\ttest: 25352.0316417\tbest: 25352.0316417 (3)\ttotal: 757ms\tremaining: 3m 8s\n",
      "4:\tlearn: 49161.8143062\ttest: 22844.4105155\tbest: 22844.4105155 (4)\ttotal: 975ms\tremaining: 3m 14s\n",
      "5:\tlearn: 47671.8469155\ttest: 20955.8305754\tbest: 20955.8305754 (5)\ttotal: 1.18s\tremaining: 3m 16s\n",
      "6:\tlearn: 46551.3894451\ttest: 19168.2753188\tbest: 19168.2753188 (6)\ttotal: 1.41s\tremaining: 3m 20s\n",
      "7:\tlearn: 46551.3894069\ttest: 19168.2101474\tbest: 19168.2101474 (7)\ttotal: 1.52s\tremaining: 3m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\tlearn: 46551.3893826\ttest: 19168.1581272\tbest: 19168.1581272 (8)\ttotal: 1.63s\tremaining: 2m 59s\n",
      "9:\tlearn: 45790.0702548\ttest: 18655.1907484\tbest: 18655.1907484 (9)\ttotal: 1.85s\tremaining: 3m 3s\n",
      "10:\tlearn: 45136.6006879\ttest: 18396.6964685\tbest: 18396.6964685 (10)\ttotal: 2.07s\tremaining: 3m 6s\n",
      "11:\tlearn: 44170.7742380\ttest: 18039.0557683\tbest: 18039.0557683 (11)\ttotal: 2.29s\tremaining: 3m 8s\n",
      "12:\tlearn: 43855.6621575\ttest: 18084.5847254\tbest: 18039.0557683 (11)\ttotal: 2.52s\tremaining: 3m 11s\n",
      "13:\tlearn: 43090.2898309\ttest: 17707.2878277\tbest: 17707.2878277 (13)\ttotal: 2.74s\tremaining: 3m 12s\n",
      "14:\tlearn: 42802.3396865\ttest: 17281.9877229\tbest: 17281.9877229 (14)\ttotal: 2.95s\tremaining: 3m 13s\n",
      "15:\tlearn: 42474.7502400\ttest: 16625.2322520\tbest: 16625.2322520 (15)\ttotal: 3.2s\tremaining: 3m 17s\n",
      "16:\tlearn: 41574.6602626\ttest: 16571.8320124\tbest: 16571.8320124 (16)\ttotal: 3.43s\tremaining: 3m 18s\n",
      "17:\tlearn: 41125.5396490\ttest: 16535.9986587\tbest: 16535.9986587 (17)\ttotal: 3.66s\tremaining: 3m 19s\n",
      "18:\tlearn: 41002.5608760\ttest: 16389.4758485\tbest: 16389.4758485 (18)\ttotal: 3.86s\tremaining: 3m 19s\n",
      "19:\tlearn: 40870.6379670\ttest: 16048.3766551\tbest: 16048.3766551 (19)\ttotal: 4.07s\tremaining: 3m 19s\n",
      "20:\tlearn: 40634.4459762\ttest: 16029.2474970\tbest: 16029.2474970 (20)\ttotal: 4.3s\tremaining: 3m 20s\n",
      "21:\tlearn: 40500.3228770\ttest: 15766.4014094\tbest: 15766.4014094 (21)\ttotal: 4.54s\tremaining: 3m 21s\n",
      "22:\tlearn: 40345.6288283\ttest: 15647.7987443\tbest: 15647.7987443 (22)\ttotal: 4.75s\tremaining: 3m 21s\n",
      "23:\tlearn: 40096.0989159\ttest: 15550.6004356\tbest: 15550.6004356 (23)\ttotal: 4.95s\tremaining: 3m 21s\n",
      "24:\tlearn: 40033.8751952\ttest: 15600.4012503\tbest: 15550.6004356 (23)\ttotal: 5.08s\tremaining: 3m 18s\n",
      "25:\tlearn: 39906.4768314\ttest: 15591.5107360\tbest: 15550.6004356 (23)\ttotal: 5.3s\tremaining: 3m 18s\n",
      "26:\tlearn: 39645.2742005\ttest: 15558.4797882\tbest: 15550.6004356 (23)\ttotal: 5.51s\tremaining: 3m 18s\n",
      "27:\tlearn: 39645.2741918\ttest: 15558.4230824\tbest: 15550.6004356 (23)\ttotal: 5.62s\tremaining: 3m 15s\n",
      "28:\tlearn: 39482.5698452\ttest: 15559.4987910\tbest: 15550.6004356 (23)\ttotal: 5.82s\tremaining: 3m 14s\n",
      "29:\tlearn: 39397.5029768\ttest: 15346.4559888\tbest: 15346.4559888 (29)\ttotal: 6.05s\tremaining: 3m 15s\n",
      "30:\tlearn: 39378.3446789\ttest: 15259.7782677\tbest: 15259.7782677 (30)\ttotal: 6.23s\tremaining: 3m 14s\n",
      "31:\tlearn: 39378.3446741\ttest: 15259.7333809\tbest: 15259.7333809 (31)\ttotal: 6.33s\tremaining: 3m 11s\n",
      "32:\tlearn: 39284.0403750\ttest: 15268.1825853\tbest: 15259.7333809 (31)\ttotal: 6.54s\tremaining: 3m 11s\n",
      "33:\tlearn: 39252.1192028\ttest: 15279.8592896\tbest: 15259.7333809 (31)\ttotal: 6.75s\tremaining: 3m 11s\n",
      "34:\tlearn: 39235.3132228\ttest: 15284.1644091\tbest: 15259.7333809 (31)\ttotal: 6.97s\tremaining: 3m 12s\n",
      "35:\tlearn: 38800.8570678\ttest: 15286.4610621\tbest: 15259.7333809 (31)\ttotal: 7.18s\tremaining: 3m 12s\n",
      "36:\tlearn: 38761.8066195\ttest: 15160.6767238\tbest: 15160.6767238 (36)\ttotal: 7.4s\tremaining: 3m 12s\n",
      "37:\tlearn: 38539.6389736\ttest: 15141.9203946\tbest: 15141.9203946 (37)\ttotal: 7.65s\tremaining: 3m 13s\n",
      "38:\tlearn: 38430.7096174\ttest: 15241.2932150\tbest: 15141.9203946 (37)\ttotal: 7.84s\tremaining: 3m 13s\n",
      "39:\tlearn: 38036.5038213\ttest: 15270.4473692\tbest: 15141.9203946 (37)\ttotal: 8.04s\tremaining: 3m 12s\n",
      "40:\tlearn: 38018.2787091\ttest: 15204.9649477\tbest: 15141.9203946 (37)\ttotal: 8.21s\tremaining: 3m 11s\n",
      "41:\tlearn: 37716.9792221\ttest: 15196.9709115\tbest: 15141.9203946 (37)\ttotal: 8.41s\tremaining: 3m 11s\n",
      "42:\tlearn: 37578.0008665\ttest: 15176.2091938\tbest: 15141.9203946 (37)\ttotal: 8.61s\tremaining: 3m 11s\n",
      "43:\tlearn: 37551.5114685\ttest: 15077.5175277\tbest: 15077.5175277 (43)\ttotal: 8.81s\tremaining: 3m 11s\n",
      "44:\tlearn: 37491.9434704\ttest: 15022.9053929\tbest: 15022.9053929 (44)\ttotal: 9.03s\tremaining: 3m 11s\n",
      "45:\tlearn: 37341.7382279\ttest: 15014.2669052\tbest: 15014.2669052 (45)\ttotal: 9.24s\tremaining: 3m 11s\n",
      "46:\tlearn: 37332.3914068\ttest: 15022.7841089\tbest: 15014.2669052 (45)\ttotal: 9.46s\tremaining: 3m 11s\n",
      "47:\tlearn: 37213.8277519\ttest: 15109.6506544\tbest: 15014.2669052 (45)\ttotal: 9.67s\tremaining: 3m 11s\n",
      "48:\tlearn: 37208.3147102\ttest: 15102.1341866\tbest: 15014.2669052 (45)\ttotal: 9.9s\tremaining: 3m 12s\n",
      "49:\tlearn: 37191.0623358\ttest: 15084.4596088\tbest: 15014.2669052 (45)\ttotal: 10.1s\tremaining: 3m 11s\n",
      "50:\tlearn: 37173.3798643\ttest: 15084.6878223\tbest: 15014.2669052 (45)\ttotal: 10.3s\tremaining: 3m 11s\n",
      "51:\tlearn: 37150.7306633\ttest: 15021.5552521\tbest: 15014.2669052 (45)\ttotal: 10.5s\tremaining: 3m 11s\n",
      "52:\tlearn: 37109.3481105\ttest: 14992.1037846\tbest: 14992.1037846 (52)\ttotal: 10.7s\tremaining: 3m 11s\n",
      "53:\tlearn: 37098.5738983\ttest: 14957.0802967\tbest: 14957.0802967 (53)\ttotal: 10.9s\tremaining: 3m 11s\n",
      "54:\tlearn: 37081.0540032\ttest: 14915.7486829\tbest: 14915.7486829 (54)\ttotal: 11.1s\tremaining: 3m 11s\n",
      "55:\tlearn: 37067.5639788\ttest: 14922.3317839\tbest: 14915.7486829 (54)\ttotal: 11.3s\tremaining: 3m 10s\n",
      "56:\tlearn: 36964.4776361\ttest: 14899.5639869\tbest: 14899.5639869 (56)\ttotal: 11.5s\tremaining: 3m 10s\n",
      "57:\tlearn: 36948.6596742\ttest: 14912.7811433\tbest: 14899.5639869 (56)\ttotal: 11.7s\tremaining: 3m 10s\n",
      "58:\tlearn: 36681.2866144\ttest: 15154.3022020\tbest: 14899.5639869 (56)\ttotal: 12s\tremaining: 3m 10s\n",
      "59:\tlearn: 36680.1671642\ttest: 15145.4515625\tbest: 14899.5639869 (56)\ttotal: 12.1s\tremaining: 3m 10s\n",
      "60:\tlearn: 36669.7124953\ttest: 15151.0809093\tbest: 14899.5639869 (56)\ttotal: 12.3s\tremaining: 3m 10s\n",
      "61:\tlearn: 36652.6392428\ttest: 15138.2532256\tbest: 14899.5639869 (56)\ttotal: 12.5s\tremaining: 3m 9s\n",
      "62:\tlearn: 36576.6452247\ttest: 15114.7055779\tbest: 14899.5639869 (56)\ttotal: 12.8s\tremaining: 3m 10s\n",
      "63:\tlearn: 36542.1332163\ttest: 15074.5031157\tbest: 14899.5639869 (56)\ttotal: 13s\tremaining: 3m 10s\n",
      "64:\tlearn: 36530.6709140\ttest: 15031.0106917\tbest: 14899.5639869 (56)\ttotal: 13.2s\tremaining: 3m 10s\n",
      "65:\tlearn: 36515.1993038\ttest: 15026.4493200\tbest: 14899.5639869 (56)\ttotal: 13.4s\tremaining: 3m 10s\n",
      "66:\tlearn: 36439.2943142\ttest: 15087.1079390\tbest: 14899.5639869 (56)\ttotal: 13.7s\tremaining: 3m 10s\n",
      "67:\tlearn: 36425.7982084\ttest: 14978.5423010\tbest: 14899.5639869 (56)\ttotal: 13.9s\tremaining: 3m 10s\n",
      "68:\tlearn: 36374.2217344\ttest: 15015.1360167\tbest: 14899.5639869 (56)\ttotal: 14.1s\tremaining: 3m 10s\n",
      "69:\tlearn: 36371.0442197\ttest: 14979.6224497\tbest: 14899.5639869 (56)\ttotal: 14.3s\tremaining: 3m 9s\n",
      "70:\tlearn: 36311.4083083\ttest: 14973.7994912\tbest: 14899.5639869 (56)\ttotal: 14.5s\tremaining: 3m 9s\n",
      "71:\tlearn: 36228.6041256\ttest: 14964.1595551\tbest: 14899.5639869 (56)\ttotal: 14.7s\tremaining: 3m 9s\n",
      "72:\tlearn: 36224.4155296\ttest: 14966.8255738\tbest: 14899.5639869 (56)\ttotal: 14.9s\tremaining: 3m 9s\n",
      "73:\tlearn: 36171.8544930\ttest: 14949.4615528\tbest: 14899.5639869 (56)\ttotal: 15.1s\tremaining: 3m 9s\n",
      "74:\tlearn: 36171.0620768\ttest: 14955.0530383\tbest: 14899.5639869 (56)\ttotal: 15.3s\tremaining: 3m 8s\n",
      "75:\tlearn: 35977.8400339\ttest: 15180.6895688\tbest: 14899.5639869 (56)\ttotal: 15.5s\tremaining: 3m 8s\n",
      "76:\tlearn: 35889.4666490\ttest: 15247.9680163\tbest: 14899.5639869 (56)\ttotal: 15.7s\tremaining: 3m 8s\n",
      "77:\tlearn: 35864.0984786\ttest: 15243.9520988\tbest: 14899.5639869 (56)\ttotal: 15.9s\tremaining: 3m 8s\n",
      "78:\tlearn: 35830.3903645\ttest: 15233.3629682\tbest: 14899.5639869 (56)\ttotal: 16.1s\tremaining: 3m 8s\n",
      "79:\tlearn: 35816.3511780\ttest: 15245.1213437\tbest: 14899.5639869 (56)\ttotal: 16.3s\tremaining: 3m 7s\n",
      "80:\tlearn: 35799.5387980\ttest: 15204.5580772\tbest: 14899.5639869 (56)\ttotal: 16.5s\tremaining: 3m 7s\n",
      "81:\tlearn: 35792.2855796\ttest: 15204.8603136\tbest: 14899.5639869 (56)\ttotal: 16.7s\tremaining: 3m 7s\n",
      "82:\tlearn: 35732.0503037\ttest: 15175.6196817\tbest: 14899.5639869 (56)\ttotal: 16.9s\tremaining: 3m 6s\n",
      "83:\tlearn: 35723.1275136\ttest: 15152.1410124\tbest: 14899.5639869 (56)\ttotal: 17.1s\tremaining: 3m 7s\n",
      "84:\tlearn: 35631.6808567\ttest: 15177.9048284\tbest: 14899.5639869 (56)\ttotal: 17.4s\tremaining: 3m 6s\n",
      "85:\tlearn: 35624.2213990\ttest: 15129.6056944\tbest: 14899.5639869 (56)\ttotal: 17.6s\tremaining: 3m 6s\n",
      "86:\tlearn: 35586.4187160\ttest: 15110.4208252\tbest: 14899.5639869 (56)\ttotal: 17.8s\tremaining: 3m 6s\n",
      "87:\tlearn: 35575.7876969\ttest: 15106.3231114\tbest: 14899.5639869 (56)\ttotal: 18s\tremaining: 3m 6s\n",
      "88:\tlearn: 35560.8047833\ttest: 15100.1952039\tbest: 14899.5639869 (56)\ttotal: 18.2s\tremaining: 3m 6s\n",
      "89:\tlearn: 35495.3593054\ttest: 15130.0414904\tbest: 14899.5639869 (56)\ttotal: 18.4s\tremaining: 3m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90:\tlearn: 35492.9057580\ttest: 15113.4630698\tbest: 14899.5639869 (56)\ttotal: 18.6s\tremaining: 3m 6s\n",
      "91:\tlearn: 35486.4660675\ttest: 15101.7844216\tbest: 14899.5639869 (56)\ttotal: 18.9s\tremaining: 3m 6s\n",
      "92:\tlearn: 35486.4660672\ttest: 15101.7737489\tbest: 14899.5639869 (56)\ttotal: 19s\tremaining: 3m 5s\n",
      "93:\tlearn: 35432.9533989\ttest: 15109.6346929\tbest: 14899.5639869 (56)\ttotal: 19.2s\tremaining: 3m 5s\n",
      "94:\tlearn: 35425.7157762\ttest: 15115.7254429\tbest: 14899.5639869 (56)\ttotal: 19.4s\tremaining: 3m 4s\n",
      "95:\tlearn: 35396.1509197\ttest: 15175.9784111\tbest: 14899.5639869 (56)\ttotal: 19.6s\tremaining: 3m 4s\n",
      "96:\tlearn: 35245.3339860\ttest: 15278.8216321\tbest: 14899.5639869 (56)\ttotal: 19.8s\tremaining: 3m 4s\n",
      "97:\tlearn: 35238.8586557\ttest: 15273.4108233\tbest: 14899.5639869 (56)\ttotal: 20s\tremaining: 3m 4s\n",
      "98:\tlearn: 35209.2352604\ttest: 15270.0240644\tbest: 14899.5639869 (56)\ttotal: 20.2s\tremaining: 3m 4s\n",
      "99:\tlearn: 34997.5862678\ttest: 15321.0384651\tbest: 14899.5639869 (56)\ttotal: 20.4s\tremaining: 3m 3s\n",
      "100:\tlearn: 34991.5708504\ttest: 15317.4218432\tbest: 14899.5639869 (56)\ttotal: 20.6s\tremaining: 3m 3s\n",
      "101:\tlearn: 34983.6677453\ttest: 15325.4585923\tbest: 14899.5639869 (56)\ttotal: 20.8s\tremaining: 3m 3s\n",
      "102:\tlearn: 34806.0958267\ttest: 15385.0451475\tbest: 14899.5639869 (56)\ttotal: 21s\tremaining: 3m 3s\n",
      "103:\tlearn: 34704.0006066\ttest: 15381.9800035\tbest: 14899.5639869 (56)\ttotal: 21.2s\tremaining: 3m 3s\n",
      "104:\tlearn: 34695.7320555\ttest: 15377.1296698\tbest: 14899.5639869 (56)\ttotal: 21.5s\tremaining: 3m 2s\n",
      "105:\tlearn: 34146.6042442\ttest: 15375.1170109\tbest: 14899.5639869 (56)\ttotal: 21.7s\tremaining: 3m 2s\n",
      "106:\tlearn: 34110.0667511\ttest: 15387.7546043\tbest: 14899.5639869 (56)\ttotal: 21.9s\tremaining: 3m 2s\n",
      "107:\tlearn: 33997.3357743\ttest: 15384.0812260\tbest: 14899.5639869 (56)\ttotal: 22.1s\tremaining: 3m 2s\n",
      "108:\tlearn: 33993.1807706\ttest: 15392.4170333\tbest: 14899.5639869 (56)\ttotal: 22.2s\tremaining: 3m 1s\n",
      "109:\tlearn: 33981.0963377\ttest: 15395.7507409\tbest: 14899.5639869 (56)\ttotal: 22.5s\tremaining: 3m 1s\n",
      "110:\tlearn: 33976.8177129\ttest: 15378.8291253\tbest: 14899.5639869 (56)\ttotal: 22.7s\tremaining: 3m 1s\n",
      "111:\tlearn: 33900.6139640\ttest: 15368.6024064\tbest: 14899.5639869 (56)\ttotal: 22.9s\tremaining: 3m 1s\n",
      "112:\tlearn: 33891.0648359\ttest: 15337.5275080\tbest: 14899.5639869 (56)\ttotal: 23.1s\tremaining: 3m 1s\n",
      "113:\tlearn: 33874.5061701\ttest: 15368.3091263\tbest: 14899.5639869 (56)\ttotal: 23.3s\tremaining: 3m 1s\n",
      "114:\tlearn: 33719.3678233\ttest: 15633.5780833\tbest: 14899.5639869 (56)\ttotal: 23.6s\tremaining: 3m 1s\n",
      "115:\tlearn: 33707.0370112\ttest: 15635.0795175\tbest: 14899.5639869 (56)\ttotal: 23.8s\tremaining: 3m 1s\n",
      "116:\tlearn: 33667.4637140\ttest: 15651.7457682\tbest: 14899.5639869 (56)\ttotal: 24s\tremaining: 3m 1s\n",
      "117:\tlearn: 33633.5658223\ttest: 15658.6882588\tbest: 14899.5639869 (56)\ttotal: 24.2s\tremaining: 3m\n",
      "118:\tlearn: 33633.4584102\ttest: 15656.6940660\tbest: 14899.5639869 (56)\ttotal: 24.3s\tremaining: 2m 59s\n",
      "119:\tlearn: 33593.5132506\ttest: 15665.3633977\tbest: 14899.5639869 (56)\ttotal: 24.5s\tremaining: 2m 59s\n",
      "120:\tlearn: 33554.2615352\ttest: 15670.0307920\tbest: 14899.5639869 (56)\ttotal: 24.8s\tremaining: 2m 59s\n",
      "121:\tlearn: 33551.1376980\ttest: 15658.3418681\tbest: 14899.5639869 (56)\ttotal: 25s\tremaining: 2m 59s\n",
      "122:\tlearn: 33534.5937981\ttest: 15657.5157042\tbest: 14899.5639869 (56)\ttotal: 25.2s\tremaining: 2m 59s\n",
      "123:\tlearn: 33531.5023665\ttest: 15644.9312416\tbest: 14899.5639869 (56)\ttotal: 25.4s\tremaining: 2m 59s\n",
      "124:\tlearn: 33480.3024198\ttest: 15632.6590020\tbest: 14899.5639869 (56)\ttotal: 25.6s\tremaining: 2m 59s\n",
      "125:\tlearn: 33469.8543438\ttest: 15629.0806895\tbest: 14899.5639869 (56)\ttotal: 25.8s\tremaining: 2m 59s\n",
      "126:\tlearn: 33466.2973877\ttest: 15627.8241666\tbest: 14899.5639869 (56)\ttotal: 26s\tremaining: 2m 58s\n",
      "127:\tlearn: 33363.2055567\ttest: 15628.3881605\tbest: 14899.5639869 (56)\ttotal: 26.2s\tremaining: 2m 58s\n",
      "128:\tlearn: 33362.5935431\ttest: 15630.5990384\tbest: 14899.5639869 (56)\ttotal: 26.5s\tremaining: 2m 58s\n",
      "129:\tlearn: 33317.5427147\ttest: 15568.3889868\tbest: 14899.5639869 (56)\ttotal: 26.7s\tremaining: 2m 58s\n",
      "130:\tlearn: 33291.4527595\ttest: 15585.0854404\tbest: 14899.5639869 (56)\ttotal: 26.9s\tremaining: 2m 58s\n",
      "131:\tlearn: 33289.9795005\ttest: 15586.0659121\tbest: 14899.5639869 (56)\ttotal: 27.1s\tremaining: 2m 57s\n",
      "132:\tlearn: 33265.3164877\ttest: 15579.5248719\tbest: 14899.5639869 (56)\ttotal: 27.3s\tremaining: 2m 57s\n",
      "133:\tlearn: 33237.1234330\ttest: 15571.6222684\tbest: 14899.5639869 (56)\ttotal: 27.5s\tremaining: 2m 57s\n",
      "134:\tlearn: 33230.6716610\ttest: 15486.2362165\tbest: 14899.5639869 (56)\ttotal: 27.7s\tremaining: 2m 57s\n",
      "135:\tlearn: 33230.6716609\ttest: 15486.2403733\tbest: 14899.5639869 (56)\ttotal: 27.8s\tremaining: 2m 56s\n",
      "136:\tlearn: 33180.0233023\ttest: 15473.9007346\tbest: 14899.5639869 (56)\ttotal: 28.1s\tremaining: 2m 56s\n",
      "137:\tlearn: 33108.4317075\ttest: 15512.2076324\tbest: 14899.5639869 (56)\ttotal: 28.2s\tremaining: 2m 56s\n",
      "138:\tlearn: 33108.4317070\ttest: 15512.1964827\tbest: 14899.5639869 (56)\ttotal: 28.3s\tremaining: 2m 55s\n",
      "139:\tlearn: 33097.7507689\ttest: 15517.1737874\tbest: 14899.5639869 (56)\ttotal: 28.6s\tremaining: 2m 55s\n",
      "140:\tlearn: 33078.5235401\ttest: 15507.6118720\tbest: 14899.5639869 (56)\ttotal: 28.8s\tremaining: 2m 55s\n",
      "141:\tlearn: 33074.0080453\ttest: 15498.3934219\tbest: 14899.5639869 (56)\ttotal: 29s\tremaining: 2m 55s\n",
      "142:\tlearn: 33040.6088049\ttest: 15506.9441263\tbest: 14899.5639869 (56)\ttotal: 29.2s\tremaining: 2m 55s\n",
      "143:\tlearn: 33016.9618464\ttest: 15491.9311800\tbest: 14899.5639869 (56)\ttotal: 29.4s\tremaining: 2m 54s\n",
      "144:\tlearn: 33006.3418895\ttest: 15485.5340881\tbest: 14899.5639869 (56)\ttotal: 29.6s\tremaining: 2m 54s\n",
      "145:\tlearn: 33005.1248845\ttest: 15481.6949660\tbest: 14899.5639869 (56)\ttotal: 29.9s\tremaining: 2m 54s\n",
      "146:\tlearn: 32703.9236559\ttest: 16309.7757721\tbest: 14899.5639869 (56)\ttotal: 30.1s\tremaining: 2m 54s\n",
      "147:\tlearn: 32699.0585366\ttest: 16301.2261494\tbest: 14899.5639869 (56)\ttotal: 30.3s\tremaining: 2m 54s\n",
      "148:\tlearn: 32625.8757888\ttest: 16281.1783891\tbest: 14899.5639869 (56)\ttotal: 30.5s\tremaining: 2m 54s\n",
      "149:\tlearn: 32622.0771674\ttest: 16294.5249519\tbest: 14899.5639869 (56)\ttotal: 30.7s\tremaining: 2m 54s\n",
      "150:\tlearn: 32575.6248486\ttest: 16311.6990961\tbest: 14899.5639869 (56)\ttotal: 30.9s\tremaining: 2m 53s\n",
      "151:\tlearn: 32557.4515903\ttest: 16303.8474076\tbest: 14899.5639869 (56)\ttotal: 31.1s\tremaining: 2m 53s\n",
      "152:\tlearn: 32447.1625224\ttest: 16419.3501027\tbest: 14899.5639869 (56)\ttotal: 31.4s\tremaining: 2m 53s\n",
      "153:\tlearn: 32444.1255481\ttest: 16417.5959949\tbest: 14899.5639869 (56)\ttotal: 31.6s\tremaining: 2m 53s\n",
      "154:\tlearn: 32411.3761935\ttest: 16446.8762882\tbest: 14899.5639869 (56)\ttotal: 31.8s\tremaining: 2m 53s\n",
      "155:\tlearn: 32404.3845403\ttest: 16459.1871444\tbest: 14899.5639869 (56)\ttotal: 32s\tremaining: 2m 53s\n",
      "156:\tlearn: 32289.1689899\ttest: 16589.6703959\tbest: 14899.5639869 (56)\ttotal: 32.3s\tremaining: 2m 53s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 14899.56399\n",
      "bestIteration = 56\n",
      "\n",
      "Shrink model to first 57 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-05 17:26:06,608]\u001b[0m Trial 0 finished with value: 8623.942169142338 and parameters: {'objective': 'RMSE', 'colsample_bylevel': 0.08318446089168269, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6083328643055512}. Best is trial 0 with value: 8623.942169142338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 1\n",
      "Best trial:\n",
      "Value: {trial.value}\n",
      "Params: \n",
      "objective: RMSE\n",
      "colsample_bylevel: 0.08318446089168269\n",
      "depth: 5\n",
      "boosting_type: Ordered\n",
      "bootstrap_type: Bernoulli\n",
      "subsample: 0.6083328643055512\n"
     ]
    }
   ],
   "source": [
    "#### CatBOOST\n",
    "\n",
    "# HyperOPT c/ Optuna \n",
    "# Nota: Esses não são os melhores hiperparametros possíveis. Talvez seja possível aumentar a precisão,\n",
    "# Mas devido ao tempo, reduzi a busca\n",
    "\n",
    "mean_error = []\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "        for mes in range(3,8):\n",
    "            \n",
    "            train = df_train[df_train['mes_referencia'] < np.datetime64(f'2020-0{mes}')]\n",
    "            val = df_train[(df_train['Ano'] == 2020) & (df_train['Mês'] == mes)]\n",
    "\n",
    "            X_train, X_test = train.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1),\n",
    "                                          val.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1)\n",
    "                \n",
    "            y_train, y_test = train['TPV_mensal'].values, val['TPV_mensal'].values\n",
    "            \n",
    "            # Setup dos hyperparametros\n",
    "            param = {\n",
    "                \"objective\": trial.suggest_categorical(\"objective\", [\"RMSE\", \"MAE\"]),\n",
    "                \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "                \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "                \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "                \"bootstrap_type\": trial.suggest_categorical(\n",
    "                    \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "                ),\n",
    "                \"used_ram_limit\": \"7gb\",\n",
    "            }\n",
    "\n",
    "            if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "                param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "\n",
    "            elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "                param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "            # Instancia o modelo\n",
    "            model_cb = cb.CatBoostRegressor(**param)\n",
    "\n",
    "            model_cb.fit(X_train, y_train,\n",
    "                         eval_set=[(X_test, y_test)],\n",
    "                         verbose=1,\n",
    "                         cat_features = ['MCC', 'MacroClassificacao',\n",
    "                                         'sub_segmento', 'persona', 'porte',\n",
    "                                         'tipo_documento', 'Estado', 'StoneCreatedDate',\n",
    "                                         'Região'],\n",
    "                         early_stopping_rounds=100)\n",
    "\n",
    "\n",
    "            pred = model_cb.predict(X_test)\n",
    "\n",
    "            error = mean_absolute_error(y_test, pred)\n",
    "            mean_error.append(error)\n",
    "        \n",
    "        return np.mean(mean_error)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, timeout=120)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"Value: {trial.value}\")\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação\n",
    "\n",
    "Uma vez que o RandomForest não foi eficiente com o dataset de treino, decidi deixa-lo de lado na validação - mesmo com o score decente. Serão validados apenas o LightGBM e o CatBOOST, com os respectivos melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Estado', 'MCC', 'MacroClassificacao', 'Região', 'StoneCreatedDate', 'persona', 'porte', 'sub_segmento', 'tipo_documento']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid's l1: 6937.43\tvalid_1's l1: 7411.84\n",
      "Mês 3 - Error 7411.84358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Estado', 'MCC', 'MacroClassificacao', 'Região', 'StoneCreatedDate', 'persona', 'porte', 'sub_segmento', 'tipo_documento']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid's l1: 5545.93\tvalid_1's l1: 7896.82\n",
      "Mês 4 - Error 7896.81773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Estado', 'MCC', 'MacroClassificacao', 'Região', 'StoneCreatedDate', 'persona', 'porte', 'sub_segmento', 'tipo_documento']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid's l1: 6959.28\tvalid_1's l1: 6745.2\n",
      "Mês 5 - Error 6745.19801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Estado', 'MCC', 'MacroClassificacao', 'Região', 'StoneCreatedDate', 'persona', 'porte', 'sub_segmento', 'tipo_documento']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid's l1: 6898.85\tvalid_1's l1: 5632.77\n",
      "Mês 6 - Error 5632.77140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Estado', 'MCC', 'MacroClassificacao', 'Região', 'StoneCreatedDate', 'persona', 'porte', 'sub_segmento', 'tipo_documento']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\bueni\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid's l1: 6756.91\tvalid_1's l1: 6036.7\n",
      "Mês 7 - Error 6036.69613\n",
      "Mean Error = 6744.66537\n"
     ]
    }
   ],
   "source": [
    "#### Validation - LightGBM\n",
    "\n",
    "# A primeira importação do lightGBM era pro hiperparametrizador\n",
    "# As únicas diferenças nessa célula são os parâmetros definidos e o DataFrame trocado \n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):\n",
    "    \n",
    "    train = df_test[df_test['mes_referencia'] < np.datetime64(f'2020-0{mes}')]\n",
    "    val = df_test[(df_test['Ano'] == 2020) & (df_test['Mês'] == mes)]\n",
    "    \n",
    "    X_train, X_test = train.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1), val.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1)\n",
    "    y_train, y_test = train['TPV_mensal'].values, val['TPV_mensal'].values\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=y_train,\n",
    "                             categorical_feature = ['MCC', 'MacroClassificacao',\n",
    "                                                    'sub_segmento', 'persona', 'porte',\n",
    "                                                    'tipo_documento', 'Estado', 'StoneCreatedDate',\n",
    "                                                    'Região'],\n",
    "                             free_raw_data=False)\n",
    "    \n",
    "    test_data = lgb.Dataset(X_test,\n",
    "                            label=y_test,\n",
    "                            reference=train_data,\n",
    "                            free_raw_data=False)\n",
    "    \n",
    "    params= {'objective': 'regression',\n",
    "            'metric': 'l1',\n",
    "            'boosting': 'gbdt',\n",
    "            'feature_pre_filter': False,\n",
    "            'lambda_l1': 0.0,\n",
    "            'lambda_l2': 0.0,\n",
    "            'num_leaves': 31,\n",
    "            'verbose': -1,\n",
    "            'feature_fraction': 0.4,\n",
    "            'bagging_fraction': 1.0,\n",
    "            'bagging_freq': 0,\n",
    "            'min_child_samples': 20,\n",
    "            'num_iterations': 1000,\n",
    "            'early_stopping_round': 100\n",
    "            }\n",
    "    \n",
    "    model_lgbm = lgb.train(params, train_data,                     \n",
    "                           valid_sets = [train_data, test_data],\n",
    "                           valid_names= ['valid'],\n",
    "                           verbose_eval = -1)\n",
    "    \n",
    "    pred = model_lgbm.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(y_test, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Validation Set - LightGBM - Scores**\n",
    "\n",
    "|  MÊS  \t|    ERROR   \t|\n",
    "|:-----:\t|:----------:\t|\n",
    "| Mês 3 \t| 7411.84358 \t|\n",
    "| Mês 4 \t| 7896.81773 \t|\n",
    "| Mês 5 \t| 6745.19801 \t|\n",
    "| Mês 6 \t| 5632.77140 \t|\n",
    "| Mês 7 \t| 6036.69613 \t|\n",
    "|  Mean \t| 6744.66537 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mês 3 - Error 6845.41871\n",
      "Mês 4 - Error 7832.15715\n",
      "Mês 5 - Error 6734.84706\n",
      "Mês 6 - Error 5356.53787\n",
      "Mês 7 - Error 6091.74392\n",
      "Mean Error = 6572.14094\n"
     ]
    }
   ],
   "source": [
    "# Validation - CatBOOST\n",
    "# As únicas diferenças nessa célula são os parâmetros definidos, o DataFrame trocado e o silence no log\n",
    "\n",
    "mean_error = []\n",
    "\n",
    "for mes in range(3,8):\n",
    "    \n",
    "    train = df_test[df_test['mes_referencia'] < np.datetime64(f'2020-0{mes}')]\n",
    "    val = df_test[(df_test['Ano'] == 2020) & (df_test['Mês'] == mes)]\n",
    "    \n",
    "    X_train, X_test = train.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1), val.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1)\n",
    "    y_train, y_test = train['TPV_mensal'].values, val['TPV_mensal'].values\n",
    "\n",
    "    \n",
    "    params= {'objective': 'MAE',\n",
    "             'colsample_bylevel': 0.08318446089168269,\n",
    "             'depth': 5,\n",
    "             'boosting_type': 'Ordered',\n",
    "             'bootstrap_type': 'Bernoulli',\n",
    "             'subsample': 0.6083328643055512\n",
    "            }\n",
    "    \n",
    "    model_cb = cb.CatBoostRegressor(logging_level='Silent',\n",
    "                                    **params)\n",
    "\n",
    "    model_cb.fit(X_train, y_train,\n",
    "                 eval_set = [(X_test, y_test)],\n",
    "                 cat_features = ['MCC', 'MacroClassificacao',\n",
    "                                 'sub_segmento', 'persona', 'porte',\n",
    "                                 'tipo_documento', 'Estado', 'StoneCreatedDate',\n",
    "                                 'Região'],\n",
    "                 early_stopping_rounds = 100)\n",
    "    \n",
    "    pred = model_cb.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(y_test, pred)\n",
    "    \n",
    "    print('Mês %d - Error %.5f' % (mes, error))\n",
    "    mean_error.append(error)\n",
    "    \n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O CatBOOST obteve o melhor score na validação pós hiper-parametrização, com **aproximadamente 23% de redução do erro do Baseline**. Utiilizarei ele para realizar a previsão dos meses não vistos (AGO-DEZ/2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsão AGO-DEZ 2020\n",
    "\n",
    "Para realizar a previsão dos meses ainda não vistos, eu criei um dataframe (utilizando o script `create_predict_df.py`) contendo todo o dataset que foi utilizado para os treinamentos e validações concatenados com os meses de Agosto a Dezembro.\n",
    "<br>\n",
    "\n",
    "Como o dataset do modelo utiliza lags de meses anteriores, tive que atualizar o TPV-Mensal nulo dos meses ainda não vistos e re-calcular o lag e a diff. Caso isso não seja feito, o modelo se comportará de forma diferente do que ocorreu nos treinamentos e na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import do Dataset com os meses finais\n",
    "df_treino_final = pd.read_csv('data/df_treino_final.csv', parse_dates = ['mes_referencia'])\n",
    "df_treino_final.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "\n",
    "df_treino_final = df_treino_final.sort_values(['mes_referencia', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBOOST não aceita NaNs na variável target\n",
    "\n",
    "df_treino_final['TPV_mensal'] = df_treino_final['TPV_mensal'].fillna(0)\n",
    "\n",
    "data_frame_list = []\n",
    "\n",
    "for mes in range(8,13):\n",
    "       \n",
    "    # Dataset de Treino\n",
    "    if mes < 10:\n",
    "        train = df_treino_final[df_treino_final['mes_referencia'] < np.datetime64(f'2020-0{mes}')]\n",
    "    \n",
    "    else:\n",
    "        train = df_treino_final[df_treino_final['mes_referencia'] < np.datetime64(f'2020-{mes}')]\n",
    "    \n",
    "    # Mês Para Previsão\n",
    "    val = df_treino_final[(df_treino_final['Ano'] == 2020) & (df_treino_final['Mês'] == mes)]\n",
    "    \n",
    "    ids = val.id.reset_index(drop = True)\n",
    "    \n",
    "    X_train, X_test = train.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1), val.drop(['id', 'TPV_mensal', 'mes_referencia'], axis=1)\n",
    "        \n",
    "    y_train, y_test = train['TPV_mensal'].values, val['TPV_mensal'].values\n",
    "    \n",
    "    # Parâmetros Definidos Anteriormente\n",
    "    \n",
    "    params= {'objective': 'MAE',\n",
    "             'colsample_bylevel': 0.08318446089168269,\n",
    "             'depth': 5,\n",
    "             'boosting_type': 'Ordered',\n",
    "             'bootstrap_type': 'Bernoulli',\n",
    "             'subsample': 0.6083328643055512\n",
    "            }\n",
    "    \n",
    "    # Instancia e Fit o modelo\n",
    "    model_cb = cb.CatBoostRegressor(logging_level='Silent',\n",
    "                                    **params)\n",
    "\n",
    "    model_cb.fit(X_train, y_train,\n",
    "                 eval_set = [(X_test, y_test)],\n",
    "                 cat_features = ['MCC', 'MacroClassificacao',\n",
    "                                 'sub_segmento', 'persona', 'porte',\n",
    "                                 'tipo_documento', 'Estado', 'StoneCreatedDate',\n",
    "                                 'Região'],\n",
    "                 early_stopping_rounds = 100)\n",
    "    \n",
    "    # Previsão -> Adiciona à lista de previsões\n",
    "    pred = model_cb.predict(X_test)\n",
    "    \n",
    "    series_pred = pd.Series(pred)\n",
    "    \n",
    "    data_frame_list.append(pd.DataFrame([ids, series_pred]).T.rename(columns = {'Unnamed 0': mes}))\n",
    "    \n",
    "    # Atualiza os valores do TPV_mensal e dos Lags criados anteriormente\n",
    "    \n",
    "    df_treino_final.loc[(df_treino_final['Ano'] == 2020) & (df_treino_final['Mês'] == mes), 'TPV_mensal'] = np.array(series_pred)\n",
    "    \n",
    "    df_treino_final['tpv_ultimo_mes'] = df_treino_final.groupby(['id'])['TPV_mensal'].shift()\n",
    "    df_treino_final['diff_ultimo_mes'] = df_treino_final.groupby(['id'])['tpv_ultimo_mes'].diff()\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        df_treino_final[f'tpv_ultimo-{i}_mes'] = df_treino_final.groupby(['id'])['TPV_mensal'].shift(i)\n",
    "        df_treino_final[f'diff_ultimo-{i}_mes'] = df_treino_final.groupby(['id'])[f'tpv_ultimo-{i}_mes'].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TPV agosto</th>\n",
       "      <th>TPV setembro</th>\n",
       "      <th>TPV outubro</th>\n",
       "      <th>TPV novembro</th>\n",
       "      <th>TPV dezembro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18,425.61</td>\n",
       "      <td>19,910.46</td>\n",
       "      <td>22,088.03</td>\n",
       "      <td>22,213.93</td>\n",
       "      <td>24,225.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21,306.29</td>\n",
       "      <td>18,895.88</td>\n",
       "      <td>17,067.83</td>\n",
       "      <td>18,202.24</td>\n",
       "      <td>16,871.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3,330.46</td>\n",
       "      <td>3,401.01</td>\n",
       "      <td>3,385.97</td>\n",
       "      <td>3,805.95</td>\n",
       "      <td>3,910.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37,006.44</td>\n",
       "      <td>36,743.90</td>\n",
       "      <td>34,987.54</td>\n",
       "      <td>36,038.05</td>\n",
       "      <td>34,502.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4,700.15</td>\n",
       "      <td>4,568.84</td>\n",
       "      <td>4,520.91</td>\n",
       "      <td>4,485.00</td>\n",
       "      <td>4,481.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205828</th>\n",
       "      <td>206326</td>\n",
       "      <td>10,270.00</td>\n",
       "      <td>9,837.63</td>\n",
       "      <td>9,621.26</td>\n",
       "      <td>9,494.06</td>\n",
       "      <td>9,066.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205829</th>\n",
       "      <td>206327</td>\n",
       "      <td>29,366.03</td>\n",
       "      <td>24,772.33</td>\n",
       "      <td>22,141.15</td>\n",
       "      <td>22,632.66</td>\n",
       "      <td>21,955.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205830</th>\n",
       "      <td>206328</td>\n",
       "      <td>4,117.87</td>\n",
       "      <td>4,070.71</td>\n",
       "      <td>3,830.54</td>\n",
       "      <td>3,931.33</td>\n",
       "      <td>3,978.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205831</th>\n",
       "      <td>206329</td>\n",
       "      <td>55,875.85</td>\n",
       "      <td>49,840.50</td>\n",
       "      <td>52,772.32</td>\n",
       "      <td>53,308.36</td>\n",
       "      <td>50,941.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205832</th>\n",
       "      <td>206330</td>\n",
       "      <td>14,806.99</td>\n",
       "      <td>14,630.33</td>\n",
       "      <td>14,726.70</td>\n",
       "      <td>14,970.49</td>\n",
       "      <td>14,927.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205833 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  TPV agosto  TPV setembro  TPV outubro  TPV novembro  \\\n",
       "0            1   18,425.61     19,910.46    22,088.03     22,213.93   \n",
       "1            2   21,306.29     18,895.88    17,067.83     18,202.24   \n",
       "2            3    3,330.46      3,401.01     3,385.97      3,805.95   \n",
       "3            4   37,006.44     36,743.90    34,987.54     36,038.05   \n",
       "4            5    4,700.15      4,568.84     4,520.91      4,485.00   \n",
       "...        ...         ...           ...          ...           ...   \n",
       "205828  206326   10,270.00      9,837.63     9,621.26      9,494.06   \n",
       "205829  206327   29,366.03     24,772.33    22,141.15     22,632.66   \n",
       "205830  206328    4,117.87      4,070.71     3,830.54      3,931.33   \n",
       "205831  206329   55,875.85     49,840.50    52,772.32     53,308.36   \n",
       "205832  206330   14,806.99     14,630.33    14,726.70     14,970.49   \n",
       "\n",
       "        TPV dezembro  \n",
       "0          24,225.63  \n",
       "1          16,871.33  \n",
       "2           3,910.12  \n",
       "3          34,502.16  \n",
       "4           4,481.43  \n",
       "...              ...  \n",
       "205828      9,066.60  \n",
       "205829     21,955.26  \n",
       "205830      3,978.83  \n",
       "205831     50,941.87  \n",
       "205832     14,927.05  \n",
       "\n",
       "[205833 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_ago_dez = data_frame_list[0].copy()\n",
    "\n",
    "for df in data_frame_list[1:]:\n",
    "    previsoes_ago_dez = previsoes_ago_dez.merge(df, on='id')\n",
    "    \n",
    "previsoes_ago_dez = previsoes_ago_dez.rename(columns = {8:'TPV agosto',\n",
    "                                                        9: 'TPV setembro',\n",
    "                                                        10: 'TPV outubro',\n",
    "                                                        11: 'TPV novembro',\n",
    "                                                        12: 'TPV dezembro'})\n",
    "\n",
    "previsoes_ago_dez['id'] = previsoes_ago_dez['id'].astype(int)\n",
    "previsoes_ago_dez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_ago_dez.to_csv('data/previsoes_ago_dez.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
